

# é¢˜ç›®è¯¦æƒ…åŠèµ„æ–™æœé›†

## èµ›é¢˜è¯¦æƒ…

https://tianchi.aliyun.com/competition/entrance/531810/introduction

![image-20200824162041743](/img/in-post/20_07/image-20200824162041743.png)



![image-20200824162108940](/img/in-post/20_07/image-20200824162108940.png)

> 14åˆ†ç±»ä»»åŠ¡
>
> æ–°é—»æ•°æ®ç‰¹ç‚¹: å…³é”®è¯å·®å¼‚å¤§, é•¿æ–‡æœ¬

![image-20200824162228930](/img/in-post/20_07/image-20200824162228930.png)

> åŒ¿åå¤„ç†äº†

![image-20200824162319572](/img/in-post/20_07/image-20200824162319572.png)

> **==åŒ¿åæ•°æ® + é•¿æ–‡æœ¬ + ç±»åˆ«ä¸å‡è¡¡==** (åŒ¿åæ•°æ®éœ€è¦ä»å¤´è®­ç»ƒè¯å‘é‡)

![image-20200824162451636](/img/in-post/20_07/image-20200824162451636.png)

![image-20200824162502328](/img/in-post/20_07/image-20200824162502328.png)

> **å…¼é¡¾å¬å›å’Œæ’åº, è€ƒè™‘æ ·æœ¬ä¸å‡è¡¡**









## èµ„æ–™ç›¸å…³

[ä¸“é¢˜ä¸€ æ¯”èµ›æ¦‚è§ˆ æ€»ç»“åŠé—®é¢˜æ”¶é›†](https://shimo.im/docs/XjgPqPPXtqXTQPGh/read)

[ã€éšå ‚æ›´æ–°ã€‘Baselineæ–‡ä»¶+PPTè¯¾ä»¶+ç›¸å…³å­¦ä¹ èµ„æ–™](https://ai.deepshare.net/detail/i_5f29620ce4b0383addfe3583/1?from=p_5f0fbc10e4b04349896c2dd9&type=6)

 [é›¶åŸºç¡€å…¥é—¨NLP.pdf](../../Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/ä¹¦ç±/NLP/é›¶åŸºç¡€å…¥é—¨NLP.pdf)  

[é˜¿æ°´è€å¸ˆäº²è‘—ã€Šæ•°æ®ç«èµ›å…¥é—¨ã€‹kaggle-101.pdf](../../Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/ä¹¦ç±/é˜¿æ°´è€å¸ˆäº²è‘—ã€Šæ•°æ®ç«èµ›å…¥é—¨ã€‹kaggle-101.pdf) 

![image-20200824133104961](/img/in-post/20_07/image-20200824133104961.png)



### [ã€éšå ‚æ›´æ–°ã€‘Baselineæ–‡ä»¶+PPTè¯¾ä»¶+ç›¸å…³å­¦ä¹ èµ„æ–™](https://ai.deepshare.net/detail/i_5f29620ce4b0383addfe3583/1?from=p_5f0fbc10e4b04349896c2dd9&type=6)

> Baselineä»£ç ï¼š
>
> é“¾æ¥ï¼šhttps://pan.baidu.com/s/1MZdm0qVUFxInMm2RVByRkg 
>
> æå–ç ï¼šw8zs 
>
> ç¬¬ä¸€æ¬¡ç›´æ’­PPTï¼š
>
> é“¾æ¥ï¼šhttps://pan.baidu.com/s/1ri3pnONIWosSbTmPduZnOg 
>
> æå–ç ï¼š3y4g 
>
> ä¸“é¢˜ä¸€ æ¯”èµ›æ¦‚è§ˆæ€»ç»“åŠé—®é¢˜
>
> æ”¶é›†ï¼šhttps://shimo.im/docs/XjgPqPPXtqXTQPGh
>
> 
>
> ç¬¬äºŒæ¬¡ç›´æ’­ä»£ç æ–‡ä»¶ï¼š
>
> é“¾æ¥ï¼šhttps://pan.baidu.com/s/1BH6aK_oMfgAA6_VsX_Ca0w 
>
> æå–ç ï¼šupcq
>
> ç¬¬äºŒæ¬¡ç›´æ’­PPT:
>
> é“¾æ¥ï¼šhttps://pan.baidu.com/s/1-SiyrxX4TGMb2zZjHmkV9g 
>
> æå–ç ï¼šaf5u
>
> é˜¿æ°´-kaggleæµç¨‹è„‘å›¾åˆ†äº«
>
> é“¾æ¥ï¼šhttps://pan.baidu.com/s/1t_bp2jEDlnlIQe7Qk-YJ7A 
>
> æå–ç ï¼šfhwp
>
> 
>
> ç¬¬ä¸‰æ¬¡ç›´æ’­ä»£ç æ–‡ä»¶ï¼š
>
> é“¾æ¥ï¼šhttps://pan.baidu.com/s/1hdymNFDnjtQYaZymcwQ9Hg 
>
> æå–ç ï¼šsfsz
>
> ç¬¬ä¸‰æ¬¡ç›´æ’­PPT:
>
> é“¾æ¥ï¼šhttps://pan.baidu.com/s/1tE6DmYLKYWEDva4GwzuTRQ 
>
> æå–ç ï¼švdec
>
> 
>
> ç¬¬å››æ¬¡ç›´æ’­ä»£ç æ–‡ä»¶ï¼š
>
> é“¾æ¥ï¼šhttps://pan.baidu.com/s/1DxYVBWRW9p9vwlZ6BESC_Q 
>
> æå–ç ï¼š30le
>
> ç¬¬å››æ¬¡ç›´æ’­PPTï¼š
>
> é“¾æ¥ï¼šhttps://pan.baidu.com/s/17GUgr7vNxYeoQIVuMQh8Hw 
>
> æå–ç ï¼ša7xd
>
> 
>
> ç¬¬äº”æ¬¡ç›´æ’­PPTï¼š
>
> é“¾æ¥ï¼šhttps://pan.baidu.com/s/12otriJ5yDyb7d3fmXypO2g 
>
> æå–ç ï¼š5tyi
>
> 
>
> ç¬¬å…­æ¬¡ç›´æ’­PPTï¼š
>
> é“¾æ¥ï¼šhttps://pan.baidu.com/s/1H1iYzkEkmuXWLd7CX62tbg 
>
> æå–ç ï¼šr5s7

### [ä¸“é¢˜ä¸€ æ¯”èµ›æ¦‚è§ˆ æ€»ç»“åŠé—®é¢˜æ”¶é›†](https://shimo.im/docs/XjgPqPPXtqXTQPGh/read)

**å®˜æ–¹æ–‡æ¡£æ°¸è¿œæ˜¯æœ€å¥½çš„å­¦ä¹ èµ„æ–™ï¼ï¼ï¼**

**å®˜æ–¹æ–‡æ¡£æ°¸è¿œæ˜¯æœ€å¥½çš„å­¦ä¹ èµ„æ–™ï¼ï¼ï¼**

 **å®˜æ–¹æ–‡æ¡£æ°¸è¿œæ˜¯æœ€å¥½çš„å­¦ä¹ èµ„æ–™ï¼ï¼ï¼**

**ğŸ°å·¥å…·ç¯‡ï¼š**

- **ä»¥pycharmä¸ºä¾‹ï¼š**

- https://www.jetbrains.com/help/pycharm/configuring-remote-interpreters-via-virtual-boxes.html

**ğŸ«pythonåº“ç¯‡ï¼š**

- **ä»¥pandasä¸ºä¾‹ï¼š**

- https://pandas.pydata.org/docs/

- **scikit-learningæ˜¯Pythonæœ€é€šç”¨çš„æœºå™¨å­¦ä¹ åº“ï¼š**

- å®˜ç½‘ï¼šhttps://scikit-learn.org/stable/index.html

- ååˆ†é’Ÿå…¥é—¨ï¼šhttps://scikit-learn.org/stable/getting_started.html

- å…¥é—¨æ•™ç¨‹ï¼šhttps://scikit-learn.org/stable/tutorial/index.html

- ç”¨æˆ·æŒ‡å—ï¼šhttps://scikit-learn.org/stable/user_guide.html#

- ä¸“ä¸šæœ¯è¯­è¡¨ï¼šhttps://scikit-learn.org/stable/glossary.html

- APIæ–‡æ¡£ï¼šhttps://scikit-learn.org/stable/modules/classes.htm

**æ€§èƒ½æŸ¥çœ‹**

`nvidia-smi`

# æ¯”èµ›æ”¶ç›Š

æ–‡æœ¬åˆ†ç±»çš„ä»»åŠ¡æ˜¯å°†ç»™å®šçš„æ–‡æœ¬åˆ’åˆ†åˆ°äº‹å…ˆè§„å®šçš„æ–‡æœ¬ç±»åˆ«ã€‚

- èµ›é¢˜éš¾åº¦ï¼š

  - åŒ¿åæ•°æ® + é•¿æ–‡æœ¬ + ç±»åˆ«ä¸å‡è¡¡ã€‚

- è§£é¢˜æ€è·¯ï¼š

  - æ€è·¯1ï¼šTF-IDF + æœºå™¨å­¦ä¹ åˆ†ç±»å™¨

  ç›´æ¥ä½¿ç”¨TF-IDFå¯¹æ–‡æœ¬æå–ç‰¹å¾ï¼Œå¹¶ä½¿ç”¨åˆ†ç±»å™¨è¿›è¡Œåˆ†ç±»ã€‚åœ¨åˆ†ç±»å™¨çš„é€‰æ‹©ä¸Šï¼Œå¯ä»¥ä½¿ç”¨SVMã€LRã€æˆ–è€…XGBoostã€‚

  - æ€è·¯2ï¼šFastText

  FastTextæ˜¯å…¥é—¨æ¬¾çš„è¯å‘é‡ï¼Œåˆ©ç”¨Facebookæä¾›çš„FastTextå·¥å…·ï¼Œå¯ä»¥å¿«é€Ÿæ„å»ºå‡ºåˆ†ç±»å™¨ã€‚

  - æ€è·¯3ï¼šWordVec + æ·±åº¦å­¦ä¹ åˆ†ç±»å™¨

  WordVecæ˜¯è¿›é˜¶æ¬¾çš„è¯å‘é‡ï¼Œå¹¶é€šè¿‡æ„å»ºæ·±åº¦å­¦ä¹ åˆ†ç±»å®Œæˆåˆ†ç±»ã€‚æ·±åº¦å­¦ä¹ åˆ†ç±»çš„ç½‘ç»œç»“æ„å¯ä»¥é€‰æ‹©TextCNNã€TextRNNæˆ–è€…BiLSTMã€‚

  - æ€è·¯4ï¼šBertè¯å‘é‡

  Bertæ˜¯é«˜é…æ¬¾çš„è¯å‘é‡ï¼Œå…·æœ‰å¼ºå¤§çš„å»ºæ¨¡å­¦ä¹ èƒ½åŠ›ã€‚

![image-20200824165103804](/img/in-post/20_07/image-20200824165103804.png)

![image-20200824161903358](/img/in-post/20_07/image-20200824161903358.png)

![image-20200824165108384](/img/in-post/20_07/image-20200824165108384.png)



![image-20200824165112916](/img/in-post/20_07/image-20200824165112916.png)

![image-20200824165122386](/img/in-post/20_07/image-20200824165122386.png)



![image-20200824165231811](/img/in-post/20_07/image-20200824165231811.png)

![image-20200824165311613](/img/in-post/20_07/image-20200824165311613.png)



![image-20200824165440109](/img/in-post/20_07/image-20200824165440109.png)



# æ¨¡å‹æ€è·¯

## æ€è·¯ + baseline1 - 0.91?

### TF-IDF TfidfVectorizer()

TF-IDF(term frequencyâ€“inverse document frequency)æ˜¯ä¸€ç§ç”¨äºä¿¡æ¯æ£€ç´¢ä¸æ•°æ®æŒ–æ˜çš„å¸¸ç”¨åŠ æƒæŠ€æœ¯ï¼Œå¸¸ç”¨äºæŒ–æ˜æ–‡ç« ä¸­çš„å…³é”®è¯ï¼Œè€Œä¸”ç®—æ³•ç®€å•é«˜æ•ˆï¼Œå¸¸è¢«å·¥ä¸šç”¨äºæœ€å¼€å§‹çš„æ–‡æœ¬æ•°æ®æ¸…æ´—ã€‚

```python
tfidf = TfidfVectorizer(ngram_range=(1, 4), max_features=5000).fit(train_df['text'].iloc[:].values)
```

> ngram_range  # ç»Ÿè®¡å¤šå°‘ä¸ªè¯ä¹‹é—´çš„çš„ç‰¹å¾
>
> max_features  # è½¬åŒ–ä¸ºå‘é‡ç‰¹å¾é•¿åº¦
>
> 
>
> train_tfidf   # Transform åè½¬åŒ–ä¸º æ ·æœ¬é‡*ç‰¹å¾ç»´åº¦çš„ç¨€ç–çŸ©é˜µ(200000\*4000)

### 3ç§æœºå™¨å­¦ä¹ æ–¹æ³•

```python

clf = RidgeClassifier()
clf = LogisticRegression()
clf = LGBMClassifier()   # LightGBM æœ‰é›†æˆå­¦ä¹ æ€æƒ³, æ•ˆæœæ¯”è¾ƒå¥½
clf.fit(train_tfidf, train_df['label'].iloc[:].values)
```

### ç¨‹åº:

```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import RidgeClassifier, LogisticRegression
from lightgbm import LGBMClassifier
import pandas as pd

!pwd
!ls ../input -lh

# train_df = pd.read_csv('../input/train_set.csv', sep='\t', nrows=4000)
# test_df = pd.read_csv('../input/test_a.csv', sep='\t', nrows=1000)
train_df = pd.read_csv('../input/train_set.csv', sep='\t', nrows=150000)
test_df = pd.read_csv('../input/test_a.csv', sep='\t', nrows=None)

# !head ../input/train_set.csv -n 2


# best 4000 features  ngram_rangeå‚æ•°, å¤šå°‘ä¸ªè¯ä¹‹é—´çš„çš„ç‰¹å¾
tfidf = TfidfVectorizer(ngram_range=(1, 4), max_features=5000).fit(train_df['text'].iloc[:].values)
train_tfidf = tfidf.transform(train_df['text'].iloc[:].values)
test_tfidf = tfidf.transform(test_df['text'].iloc[:].values)

# clf = RidgeClassifier()
# clf = LogisticRegression()
clf = LGBMClassifier()   
clf.fit(train_tfidf, train_df['label'].iloc[:].values)

df = pd.DataFrame()
df['label'] = clf.predict(test_tfidf)
df.to_csv('submit_2.csv', index=None)
```

### èµ›é¢˜æ€è·¯

![image-20200824162610114](/img/in-post/20_07/image-20200824162610114.png)



![image-20200824163334972](/img/in-post/20_07/image-20200824163334972.png)

![image-20200824163411405](/img/in-post/20_07/image-20200824163411405.png)

![image-20200824163442843](/img/in-post/20_07/image-20200824163442843.png)

![image-20200824163459813](/img/in-post/20_07/image-20200824163459813.png)

![image-20200824163514159](/img/in-post/20_07/image-20200824163514159.png)

![image-20200824163532826](/img/in-post/20_07/image-20200824163532826.png)

![image-20200824163546770](/img/in-post/20_07/image-20200824163546770.png)

![image-20200824163612563](/img/in-post/20_07/image-20200824163612563.png)

![image-20200824164933654](/img/in-post/20_07/image-20200824164933654.png)

![image-20200824165057559](/img/in-post/20_07/image-20200824165057559.png)

> 10000è®­ç»ƒæ ·æœ¬



## Baseline2 

### filterå‡½æ•°

Python è¯­è¨€æä¾› `filter()` å‡½æ•°ï¼Œè¯­æ³•å¦‚ä¸‹ï¼š

    filter(function, sequence) 

`filter()` å‡½æ•°çš„åŠŸèƒ½ï¼šå¯¹ sequence ä¸­çš„ item **ä¾æ¬¡**æ‰§è¡Œ function(item)ï¼Œå°†ç»“æœä¸º True çš„ item ç»„æˆä¸€ä¸ª List/String/Tupleï¼ˆå–å†³äº sequence çš„ç±»å‹ï¼‰å¹¶è¿”å›ã€‚æœ‰äº†è¿™ä¸ªå‡½æ•°ï¼Œä¸Šé¢çš„ä»£ç å¯ä»¥ç®€åŒ–ä¸ºï¼š

    divide_by_three = lambda x : True if x % 3 == 0 else False selected_numbers = filter(divide_by_three, range(1, 11)) 

å°† lambda è¡¨è¾¾å¼æ”¾åœ¨è¯­å¥ä¸­ï¼Œä»£ç ç®€åŒ–åˆ°åªéœ€è¦ä¸€å¥è¯å°±å¤Ÿäº†ï¼š    

    selected_numbers = filter(lambda x: x % 3 == 0, range(1, 11))

### DataFrame.applyå‡½æ•°

[applyå‡½æ•°](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html#pandas.DataFrame.apply)æ˜¯`pandas`é‡Œé¢æ‰€æœ‰å‡½æ•°ä¸­è‡ªç”±åº¦æœ€é«˜çš„å‡½æ•°ã€‚è¯¥å‡½æ•°å¦‚ä¸‹ï¼š

```
DataFrame.apply(func, axis=0, broadcast=False, raw=False, reduce=None, args=(), **kwds)
```

> è¯¥å‡½æ•°æœ€æœ‰ç”¨çš„æ˜¯ç¬¬ä¸€ä¸ªå‚æ•°ï¼Œè¿™ä¸ªå‚æ•°æ˜¯å‡½æ•°ï¼Œç›¸å½“äº`C/C++`çš„å‡½æ•°æŒ‡é’ˆã€‚
>
> è¿™ä¸ªå‡½æ•°éœ€è¦è‡ªå·±å®ç°ï¼Œå‡½æ•°çš„ä¼ å…¥å‚æ•°æ ¹æ®`axis`æ¥å®šï¼Œæ¯”å¦‚`axis = 1`ï¼Œå°±ä¼šæŠŠä¸€è¡Œæ•°æ®ä½œä¸º`Series`çš„æ•°æ®ç»“æ„ä¼ å…¥ç»™è‡ªå·±å®ç°çš„å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬åœ¨å‡½æ•°ä¸­å®ç°å¯¹`Series`ä¸åŒå±æ€§ä¹‹é—´çš„è®¡ç®—ï¼Œè¿”å›ä¸€ä¸ªç»“æœï¼Œåˆ™`apply`å‡½æ•°ä¼šè‡ªåŠ¨éå†æ¯ä¸€è¡Œ`DataFrame`çš„æ•°æ®ï¼Œæœ€åå°†æ‰€æœ‰ç»“æœç»„åˆæˆä¸€ä¸ª`Series`æ•°æ®ç»“æ„å¹¶è¿”å›ã€‚



`DataFrame.apply()` å‡½æ•°åˆ™ä¼šéå†æ¯ä¸€ä¸ªå…ƒç´ ï¼Œå¯¹å…ƒç´ è¿è¡ŒæŒ‡å®šçš„ functionã€‚æ¯”å¦‚ä¸‹é¢çš„ç¤ºä¾‹ï¼š

```python
import pandas as pd
import numpy as np

matrix = [
    [1,2,3],
    [4,5,6],
    [7,8,9]
]

df = pd.DataFrame(matrix, columns=list('xyz'), index=list('abc'))
df.apply(np.square)
```



å¦‚æœåªæƒ³ `apply()` ä½œç”¨äºæŒ‡å®šçš„è¡Œå’Œåˆ—ï¼Œå¯ä»¥ç”¨è¡Œæˆ–è€…åˆ—çš„ `name` å±æ€§è¿›è¡Œé™å®šã€‚æ¯”å¦‚ä¸‹é¢çš„ç¤ºä¾‹å°† x åˆ—è¿›è¡Œå¹³æ–¹è¿ç®—ï¼š

```python
df.apply(lambda x : np.square(x) if x.name=='x' else x)
```

```swift
    x  y  z
a   1  2  3
b  16  5  6
c  49  8  9
```

ä¸‹é¢çš„ç¤ºä¾‹å¯¹ x å’Œ y åˆ—è¿›è¡Œå¹³æ–¹è¿ç®—ï¼š

```python
df.apply(lambda x : np.square(x) if x.name in ['x', 'y'] else x)
```

```swift
    x   y  z
a   1   4  3
b  16  25  6
c  49  64  9
```

ä¸‹é¢çš„ç¤ºä¾‹å¯¹ç¬¬ä¸€è¡Œ ï¼ˆa æ ‡ç­¾æ‰€åœ¨è¡Œï¼‰è¿›è¡Œå¹³æ–¹è¿ç®—ï¼š

```python
df.apply(lambda x : np.square(x) if x.name == 'a' else x, axis=1)
```

é»˜è®¤æƒ…å†µä¸‹ `axis=0` è¡¨ç¤ºæŒ‰åˆ—ï¼Œ`axis=1` è¡¨ç¤ºæŒ‰è¡Œã€‚

### NLPåŸºç¡€ - ç¬”è®°åœ¨notibality

1. éç»“æ„åŒ–æ•°æ®ä¸éœ€è¦å¾ˆå¤šEDA, ç›¸ååœ¨ç»“æ„åŒ–æ•°æ®ä¸­å¾ˆéœ€è¦
2. é¢„å¤„ç†æ–¹å¼
3. å¥å­æˆªå–å’Œå¡«å……, ä½¿ç»´åº¦ä¸€è‡´æ¥è®­ç»ƒæ¨¡å‹

### é¢„è®­ç»ƒè¯å‘é‡æ–¹æ³•

: fasttext, word2vec, glove, bert

### åˆ†ç±»æ¨¡å‹: 

![image-20200826173312260](/img/in-post/20_07/image-20200826173312260.png)

### TF-IDF: 

1. N-gram , æ˜¯ä¸€ç§è¯­è¨€æ¨¡å‹, åˆ©ç”¨æ»‘çª—æ€æƒ³ç»Ÿè®¡é¢‘ç‡
2. Countvectorizer, å°†æ–‡æœ¬ç¼–ç å¹¶ç»Ÿè®¡, ç»Ÿè®¡è¯çš„æ•°é‡(å¯¹åº”CVä¸­ç‰¹å¾çš„æ•°é‡)
3. æ¨¡å‹å’Œå…¬å¼:
   ![image-20200826173729123](/img/in-post/20_07/image-20200826173729123.png)
   ![image-20200826173751785](/img/in-post/20_07/image-20200826173751785.png)

### è¯å‘é‡

![image-20200826174032183](/img/in-post/20_07/image-20200826174032183.png)
![image-20200826174153466](/img/in-post/20_07/image-20200826174153466.png)

### fastText

![image-20200826174130572](/img/in-post/20_07/image-20200826174130572.png)

### TextCNN

![image-20200826174105045](/img/in-post/20_07/image-20200826174105045.png)

### ç»Ÿè®¡æœ€å¤šçš„å­—ç¬¦æ•°

```python
# æ‹¼æ¥è®­ç»ƒé›†æ–‡æœ¬å’Œæµ‹è¯•é›†æ–‡æœ¬ï¼Œåˆ†è¯ï¼Œæ‰¾åˆ°æœ€å¤§çš„word
all_lines = ' '.join(train_df['text']) + ' ' + ' '.join(test_df['text'])
all_words = np.array(all_lines.split()).astype(int)

all_words.max()
# è¾“å‡º7579ï¼Œ è¯´æ˜æ€»å…±åŒ…å«7550ä¸ªå­—ç¬¦
```

### åŠ å…¥5æŠ˜äº¤å‰éªŒè¯å¹¶è¾“å‡ºæœ€ä½³çš„é¢„æµ‹

```python
# max_features, ngram_range 3 å°±å¤Ÿäº†
tfidf = TfidfVectorizer(ngram_range=(1, 3), max_features=10000).fit(train_df['text'].iloc[:].values)
train_tfidf = tfidf.transform(train_df['text'].iloc[:].values)
test_tfidf = tfidf.transform(test_df['text'].iloc[:].values)

# 5æŠ˜äº¤å‰éªŒè¯
skf = StratifiedKFold(n_splits=5, random_state=7) 
test_pred = np.zeros((test_tfidf.shape[0], 14), dtype=np.float32)  
for idx, (train_index, valid_index) in enumerate(skf.split(train_tfidf, train_df['label'].values)):

    x_train_, x_valid_ = train_tfidf[train_index], train_tfidf[valid_index]
    y_train_, y_valid_ = train_df['label'].values[train_index], train_df['label'].values[valid_index]
    
    clf = LGBMClassifier()
    clf.fit(x_train_, y_train_)
    val_pred = clf.predict(x_valid_)
    
    print(f1_score(y_valid_, val_pred, average='macro'))
    test_pred += clf.predict_proba(test_tfidf)

    
df = pd.DataFrame()
df['label'] = test_pred.argmax(1)
df.to_csv('submit.csv', index=None)
```

## Baseline3 ç«èµ›æµç¨‹ä¸pipline - baselineå¼ºåŒ–

ä»»åŠ¡åç§°ï¼šæ¨¡å‹è®­ç»ƒä¸äº¤å‰éªŒè¯

ä»»åŠ¡è¯¦è§£ï¼š

1. å¯¹ç†è§£3ä¸­æ•°æ®åˆ’åˆ†æ–¹æ³•ä¼˜ç¼ºç‚¹ï¼›
2. å­¦ä¹ ä½¿ç”¨sklearnä¸­çš„æ•°æ®åˆ’åˆ†æ–¹æ³•ï¼›

### ç«èµ›æµç¨‹

![image-20200826225144128](/img/in-post/20_07/image-20200826225144128.png)

![image-20200826225449586](/img/in-post/20_07/image-20200826225449586.png)



1. èµ›é¢˜ç±»å‹å’Œä¸åŒè¯„ä¼°æ–¹å¼
2. å­—æ®µåˆ†å¸ƒåˆ†æ
3. æ•°æ®åˆ†æ
4. ç‰¹å¾å·¥ç¨‹
5. æœºå™¨å­¦ä¹ æ¨¡å‹
6. æ¨¡å‹é›†æˆæ–¹æ³•
7. æ¨¡å‹è®­ç»ƒéªŒè¯
8. ==**ä¼ªæ ‡ç­¾æ–¹æ³•, æ¦‚ç‡å€¼ç­‰**==
9. ç¼“è§£è¿‡æ‹Ÿåˆæ–¹æ³•
10. äº†è§£æ¨¡å‹ä¸Šé™
11. æ•°æ®åˆ’åˆ†æ–¹æ³•
12. æ–‡æœ¬æ•°æ®æ‰©å¢æ–¹æ³•
13. åˆ†å¸ƒä¸€è‡´æ€§(CV, LB)

### æ•°æ®åˆ’åˆ†æ–¹å¼

ä¸»è¦ç”¨SKF

```python
# hold-out
from sklearn.model_selection import train_test_split

# KæŠ˜äº¤å‰éªŒè¯
from sklearn.model_selection import KFold
from sklearn.model_selection import RepeatedKFold

# KæŠ˜åˆ†å¸ƒä¿æŒäº¤å‰éªŒè¯, å¥½
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import RepeatedStratifiedKFold

# æ—¶é—´åºåˆ—åˆ’åˆ†æ–¹æ³•
from sklearn.model_selection import TimeSeriesSplit

# booststrap é‡‡æ ·
from sklearn.utils import resample
```

### fasttextä»£ç 

### ==å¯¹æŠ—éªŒè¯==

```python
from sklearn.feature_extraction.text import TfidfVectorizer
train_df = pd.read_csv('../input/train_set.csv', sep='\t', nrows=5000)
test_df = pd.read_csv('../input/test_a.csv', sep='\t', nrows=5000)

tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=500).fit(train_df['text'].iloc[:].values)
train_tfidf = tfidf.transform(train_df['text'].iloc[:].values)
test_tfidf = tfidf.transform(test_df['text'].iloc[:].values)


# æ‹¼æ¥è®­ç»ƒçš„tfidfå’Œæµ‹è¯•çš„tfidf
train_test = np.vstack([train_tfidf.toarray(), test_tfidf.toarray()])



# æ ‡ç­¾ä¸º 1 å’Œ 0
lgb_data = lgb.Dataset(train_test, label=np.array([1]*5000+[0]*5000))

params = {}
params['max_bin'] = 10
params['learning_rate'] = 0.01
params['boosting_type'] = 'gbdt'
params['metric'] = 'auc'

result = lgb.cv(params, lgb_data, num_boost_round=100, nfold=3, verbose_eval=20)	

pd.DataFrame(result)
```

## ä¸åŠ bertä¸Šé™ 0.96

## åŠ bertä¸Šé™ 0.98å·¦å³

## åŠ ä¼ªæ ‡ç­¾

## berté¢„è®­ç»ƒæ¨¡å‹è®²è§£



![image-20200908230948217](/img/in-post/20_07/image-20200908230948217.png)



![image-20200908231341062](/img/in-post/20_07/image-20200908231341062.png)

![image-20200908232450512](/img/in-post/20_07/image-20200908232450512.png)

![image-20200908232949639](/img/in-post/20_07/image-20200908232949639.png)











