---
layout: post
comments: true
mathjax: false
subtitle: ''
author: "Sun"
header-style: text
tags:
  - 比赛项目	
  - 
  - 
---

# 腾讯广告算法大赛-top3

## 赛题理解

![image-20200819201948741](/img/in-post/20_07/image-20200819201948741.png)

## 特征构造

特征工程 -> 刻画label

![image-20200819202804121](/img/in-post/20_07/image-20200819202804121.png)

> 刻画用户比较难, 可以做可解释性
>
> 1. 点击次数: 刻画活跃度
> 2. 每日平均点击数: 
> 3. 用户在三个月内的点击分布: 
>
> 广告id特征, 进行特征编码, 类别特征越多, 做label encoding 效果越好, 
>
> 1. 比如统计广告id被不同年龄性别点击次数 -> ==类似于word2vec,转为向量表示==
> 2. 注意:
>    1. 不要信息泄露(训练的时候蕴含了label信息) 
>       1. ==可以进行5折提取特征??== -label encoding, 即用前四个预测后一个鞥.
> 3. 编码特征
>    1. ==TFIDF????==
>    2. lgb -> DL 

## 传统方案介绍

![image-20200819204354813](/img/in-post/20_07/image-20200819204354813.png)

> 用lr进行stacking, 拟合权重,比如$out = 0.4m_1+0.3m_2+0.3m_3$,

## 模型介绍



![image-20200819204946580](/img/in-post/20_07/image-20200819204946580.png)

<img src="/img/in-post/20_07/image-20200819204935498.png" alt="image-20200819204935498" style="zoom:67%;" />

> 下图为用户点击序列
>
> **enbedding** 将序列训练成词向量
>
> LSTM  类似于编码器的作用
>
> 

#### 增加多样性方式:dropout(数据增强)

embading多样性和样本多样性, 如dropout![image-20200819205814238](/img/in-post/20_07/image-20200819205814238.png)

![image-20200819210218654](/img/in-post/20_07/image-20200819210218654.png)

> ==使用了3层的dropout, 可以对向量预测多次, 对多次结果求平均. 最后优化整个loss, 可以加速模型收敛, 提高泛化能力==

![image-20200819210701491](/img/in-post/20_07/image-20200819210701491.png)

> 1. 交叉熵损失:
>
> ![image-20200819210634508](/img/in-post/20_07/image-20200819210634508.png)
>
> onehot编码时, 原来只计算了一个损失,    加入标签平滑后, 会增大惩罚
>
> 2. 类别有一定相关性时, 可以使其向山峰靠拢如[0.01,0.02,0.1,0.8,0.1 ,…]:
>
>    ![image-20200819211117366](/img/in-post/20_07/image-20200819211117366.png)

#### 预训练—attention,突出强特

![image-20200819215744323](/img/in-post/20_07/image-20200819215744323.png)

怎么抽广告特征id — 用预训练模型, 类似于PCA挑出来重要的特征, 使用预训练方式预训练attention

![image-20200819212936445](/img/in-post/20_07/image-20200819212936445.png)

> attention向量是128*1 , 可以得到每个广告特征的重要性
>
> 表现在 用部分广告id就可以进行进行预测

#### 滑动窗口 — 有点类似cnn， 用部分数据得到特征

![image-20200819213338287](/img/in-post/20_07/image-20200819213338287.png)

> **方案一**： 将用户序列阶段， 分成多序列， 增加样本数量且可以抗干扰
>
> 滑动10次，得到10条样本，数据增强
>
> 类似于融合， 抗干扰
>
> 不过缺点是可能得到的是部分信息

#### bert

对bert,空缺预测,

#### 模型差异性

![image-20200819214614474](/img/in-post/20_07/image-20200819214614474.png)

####  显示推荐和隐式推荐

年龄,性别等拿到后再进行的推荐是显示推荐

## 经验分享

![image-20200819215929398](/img/in-post/20_07/image-20200819215929398.png)

![image-20200819220240144](/img/in-post/20_07/image-20200819220240144.png)











