---
layout: post
comments: true
mathjax: false
subtitle: '强化学习'
author: "Sun"
header-style: text
tags:
  - RL
  - 
  - 
---

# 理论

## 强化学习

1. 分数导向性, 分数类似于监督学习的标签
2.  分类
   ![image-20201009171448002](/img/in-post/20_07/image-20201009171448002.png)
   1. 理解环境/不理解环境
   2. 基于概率/基于价值 -> ==Actor-Critic==
      ![image-20201009171811759](/img/in-post/20_07/image-20201009171811759.png)
   3. ==回合更新/单步更新==
      ![image-20201009172019366](/img/in-post/20_07/image-20201009172019366.png)
      ![image-20201009172125347](/img/in-post/20_07/image-20201009172125347.png)
   4. 在线学习/离线学习
      ![image-20201009172241594](/img/in-post/20_07/image-20201009172241594.png)
      ![image-20201009172255551](/img/in-post/20_07/image-20201009172255551.png)



## 介绍

1. 模拟环境编写: tkinter/gym
2. 

# Q-Learning

![image-20201009173557136](/img/in-post/20_07/image-20201009173557136.png)
$$
Q(s,a) <-Q(s,a)+α[r+γmax_{a^{'}}Q(s',a')-Q(s,a)]
$$

> Q现实 = 当前奖励 + 衰减*最大的Q估计
>
> ε-greedy: 一种学习策略,用ε概率(如90%)按照Q表最优值选择
>
> α: 学习效率
>
> γ: 衰减系数, 越大越有远见
>
> ![image-20201009181946022](/img/in-post/20_07/image-20201009181946022.png)

# 实例1/2 — 走迷宫

# sarsa

1. 比较保守
2. 



























