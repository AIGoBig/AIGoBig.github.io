# 面试经验

## Deecamp(30m)

1. 自我介绍, 项目介绍
2. 项目里的垃圾分类是用什么方法实现的？
   1. 注意讲方法, 创新点
3. pytorch - 使用迁移训练, 冻结模型的方法？
   1. (应该是auto_grad=0)
   2. 平常多写代码, 多做项目
4. √  算法 - 斐波那契数列(动态规划) 

##  内推-旷视(50m)

1. 自我介绍, 项目介绍
2. 项目里AutoML等是什么作用的
   1. 注意项目的写法, 平常多积累熟悉的项目写上去
   2. 项目相关性要强, 其他的写好说明放在简历里
3. **DL原理 - BN层的数学原理？**
   1. 大胆说出来, 注意要**思路尽量清晰**
   2. 总结原理, 能手推公式, 手写代码
4. 算法 - 数字转化为字母
   1. (应将其看做进制的方法)
   2. 就算是不会写的也要尝试将思路说清楚
5. `一定提前做好充分准备`
   1. 电脑充满电
   2. 带好演算纸
   3. 打开代码编译器

## 滴滴电话面

1. 一般都用什么激活函数？

   1. Relu，softmax

2. 激活函数的作用是什么？

   1. 如果不用激励函数，每一层输出都是上层输入的线性函数，无论神经网络有多少层，输出都是输入的线性组合。激活函数给神经元引入了非线性因素，使得神经网络可以任意逼近任何非线性函数，这样神经网络就可以应用到众多的非线性模型中。
   2. 防止梯度弥散的发生，ReLU缓解了梯度消失的问题。

3. 如何防止过拟合？

   1. 数据增强
   2. 参数正则化
   3. 模型集成
      1. Dropout
         1. 相当于每次都在训练不同结构的神经网络
         2. 类比bagging，可被认为是一种大规模深度神经网络的模型集成方法
         3. 轻量级的bagging集成近似
   4. 批量归一化（Batch Normalization）

4. GBDT防止过拟合的方法？

   

## 讯飞电话面

1. 精度通过换模型提高了20%太高了吧？
   1. 没有控制变量，其实数据也是一直在增加的
2. resNet从梯度角度解释优势？
   1. 
3. EfficientNet原理？
   1. 
4. BN原理？
   1. NN本质是学习数据分布，有两种分布不同：
      训练集和测试集数据分布不同，降低泛化能力。
      随着网络训练，隐层网络参数变化会使网络在每次迭代拟合不同的分布，增大复杂度且易过拟合
   2. 数学原理：（x-均值）/标准差
5. Mixup增强 
6. MixNet模型了解过吗
7. XGBoost原理
8. 科大讯飞比赛里，特征交叉是怎么实现的？

## 百度nlp电话面

1. 推荐项目做了什么？
2. 二维矩阵找数字，想如何可以降低复杂度，二分法
3. 

## momento电话面

1. 说一下归并排序算法？
2. 

## 腾讯面

2个算法题，都说了思路没完全写出来

1. 有序链表合并

2. 矩阵最小路径-动态规划

   

## 寒武纪面

1. 损失函数还用过哪些，距离函数余弦和欧式有什么区别
2. pytorch - detach的作用是什么
3. KL散度和交叉熵什么区别？
4. BN层具体原理是什么？哪些参数可以调整

## 百度

nlp多模态

## Monento 

10点到9点 一周六天

## 腾讯 

多模态







# 经历经验

## Deecamp反思：

1. 以后有重要事情马上做不要拖！积极很关键，抓紧看信息，抓紧组队很重要！

2. 当时错过组队时机主要有以下原因：

   1. 当时在写帮学长下论文的程序 → 把**时间花在最重要的事情上**，OKR法则
   2. 纠结于拍照片和选哪一个赛题 → 做决定不要犹豫

3. 赛题应该选与自己方向相关的，方向好的。

4. 好的队友甚至比好的赛题更重要，积极性很重要，团队积极性的好坏约等于获胜的概率。

5. 广结优秀的人，不要怕会被别人注意，努力变的优秀


# 面试问项目遇到的问题准备

## 问题1：什么是指针丢失和内存泄漏？

### 在插入结点时，一定要注意操作的顺序。

因为操作不当的时候，很容易造成指针丢失。比如a ->b之间插入一个c，同时不注意的时候很容易这么写

```
//声明一个p;
p->next = c;  // 将 p 的 next 指针指向 c 结点; 
c->next = p->next;  // 将 c 的结点的 next 指针指向 b 结点;
```

这就很容易让链表断成两半，造成指针丢失。正确的写法是将二三两行代码顺序换过来即可。

### 删除链表结点时，也一定要记得手动释放内存空间。

和插入一样，如果不及时释放内存空间，积少成多，很容易造成内存泄漏。

### 技巧：利用哨兵节点简化实现难度

哨兵节点主要是处理边界问题的，并不直接参与业务逻辑，当引入哨兵节点的时候，不管链表是不是空，head 指针都会一直指向这个哨兵结点。我们也把这种有哨兵结点的链表叫**带头链表**。相反，没有哨兵结点的链表就叫作**不带头链表**。



## 大数据 释放内存方法,

1、None方法
2、cell方法
3、运行脚本：
import gc; gc.collect()

## 释放显存等-kill

nvidia-smi

每次用完jupyter ，明明已经退出了，但还是占着显存，用nvidia-smi查看，发现确实pyhton命令还在占着全部显存的进程

找到那个对应的PID， 执行**kill**命令，比如进程号PID是5186

kill 5186就可以了















