# 动机

文章指出，用户兴趣有以下两个特点：

**多样性**：即每个用户在浏览购物网站的时候可能会对不同的商品感兴趣。

**局部聚集性：**由于用户兴趣具有多样性，所以**只有部分用户历史行为对是否点击有帮助**。

> 比如系统给年轻小伙推荐一款新款篮球鞋，他是否点击只跟他之前买过护膝、球衣的历史行为有关，而与他是否购买过电脑、手机的历史行为无关。

CTR预测是工业应用中常见的任务。常见的深度学习的基线模型是将Embedding&MLP相结合：

1. 首先，将大规模的稀疏特征映射为低维度的embedding向量；
2. 然后用group-wise将其转换为长度固定的向量；
3. 最后将这些向量连接在一起喂入MLP学习特征间的非线性关系。

但是这种模型存在一定的**缺陷**：不论候选ad是什么，用户特征都被压缩为固定长度的表示向量(这限制了Embedding&MLP的表达能力)，这很难从有效的从历史行为数据中捕获用户的多样性兴趣。

论文作者提出了DIN模型，即深度兴趣网络，它**通过设计局部激活单元自适应的从历史行为中学习用户的兴趣表示**。DIN通过引入一个局部激活单元，通过软搜索历史行为的相关部分来关注相关的用户兴趣，并采用**加权和池**来获得用户兴趣相对于候选广告的表示，**与候选广告相关性越高的行为的激活权重越大，并在用户兴趣的表示中占主导地位。**实际上就是增加了Attention机制。此外，文中还提出了新的正则化方法以及激活函数。

# 简介

**想要解决的问题**

在’embedding＆MLP’这一传统网络模型的范式中, 无论候选广告是什么，用户特征都被压缩为**固定长度**的特征向量。 固定长度向量的使用将成为瓶颈，这将使Embedding＆MLP方法**难以有效地从丰富的历史行为中捕获用户的各种兴趣。**

**提出方法**

深度兴趣网络（DIN）通过设计**本地激活单元（local activation unit）**来适应性地解决这一挑战，它可以从历史行为（针对特定广告）自适应地学习用户兴趣的表示形式。该表示向量随不同广告而变化，极大地提高了模型的表达能力。

因此，DIN利用attention机制对用户历史行为进行了不同的加权处理，针对不同的广告，用户历史行为的权重不一致。

# 数据特征

DIN构建的特征分为四类：分别是**用户特征、用户行为特征、广告特征、上下文特征**。特征均被变换为one-hot或者multi-hot形式的数据。然后，通过DNN学习数据之间的交叉特征。

<img src="/img/in-post/20_07/image-20201231173547597.png" alt="image-20201231173547597" style="zoom:50%;" />



# 网络结构

## 一般的DNN网络：

<img src="/img/in-post/20_07/image-20201231174753217.png" alt="image-20201231174753217" style="zoom:50%;" />

> - ***Embedding Layer*:** 原始数据是**高维且稀疏**的0-1矩阵，emdedding层用于将原始高维数据压缩成低维矩阵；
> - ***Pooling Layer* :** 由于不同的用户有不同个数的行为数据，导致embedding矩阵的向量大小不一致，而全连接层只能处理固定维度的数据，因此，**利用Pooling Layer得到一个固定长度的向量。**                   ![img](/img/in-post/20_07/20181214171200424.png)
>
> - ***Concat Layer:*** 经过embedding layer和pooling layer后，原始稀疏特征被转换成多个**固定长度**的用户兴趣的抽象表示向量，然后利用concat layer**聚合抽象表示向量**，输出该用户兴趣的唯一抽象表示向量；
> - ***MLP*：**将concat layer输出的抽象表示向量作为MLP的输入，**自动学习数据之间的交叉特征**；
> - ***Loss*：**损失函数一般采用Loglos：  ![img](/img/in-post/20_07/20181214172811414.png)

传统DNN模型在`Embedding Layer -> Pooling Layer`得到用户兴趣表示的时候，**没有考虑用户与广告之间的关系，即不同广告之间的权重是一致的。**之前也分析过，这样是有问题的。

## DIN网络结构：

因此，DIN利用attention机制，**在得到用户兴趣表示时赋予不同的历史行为不同的权重**，即通过`Embedding Layer -> Pooling Layer+attention`实现局部激活。从最终反向训练的角度来看，就是根据当前的候选广告，来反向的激活用户历史的兴趣爱好，赋予不同历史行为不同的权重。

![image-20201231193030115](/img/in-post/20_07/image-20201231193030115.png)

DIN认为用户的兴趣不是一个点，而是一个多峰的函数。一个峰就表示一个兴趣，峰值的大小表示兴趣强度。那么针对不同的候选广告，用户的兴趣强度是不同的，也就是说**随着候选广告的变化，用户的兴趣强度不断在变化**。 

**attention的公式如下：**

<img src="/img/in-post/20_07/image-20201231194657633.png" alt="image-20201231194657633" style="zoom:50%;" />

> 其中，$e_i$表示用户U历史行为序列的embedding向量，$v_A$是候选广告A的embedding向量，$v_U(A)$因不同广告而异。 $a()$是一个前馈网络，其输出作为**激活权重**，如图2所示。 除了两个输入嵌入向量之外， $a()$将它们的乘积相加以馈入后续网络，这是帮助进行关联建模的显式知识。
>
>  $w_j$表示$e_j$的权重，$v_U$表示用户所有行为embedding向量的加权和，表示用户的兴趣。**候选广告影响着每个behavior id的权重，也就是Local Activation**。权重表示的是：每一个behavior id针对当前的候选广告Va，对总的用户兴趣表示的Embedding Vector的贡献大小。在实际实现中，权重用激活函数Dice的输出来表示，输入是Vi和Va。

# 自适应激活函数Dice

DIN提出了一种数据动态自适应激活函数Dice，认为**分割点**不是固定为0的，而是随着数据不同而动态变化的。 Dice公式如下：![img](/img/in-post/20_07/20181214175430504.png)

ps的计算分为两步：

- 对进行正态分布归一化处理，使得数据集中在正态分布均值处；
- 利用sigmoid函数归一化，使得输出在0~1之间。

f(s)的作用可以理解为一种平滑操作，alpha是一个超参数，推荐值为0.99。

# 高效正则器

由于DNN模型往往十分复杂，而且参数较多。利用L1,L2等正则手段往往加重了模型过拟合，DIN提出了一种高效的正则方法：

![img](/img/in-post/20_07/20181214183516390.png)

# 总结

DIN通过引入attention机制，针对不同的广告构造不同的用户抽象表示，从而**实现了在数据维度一定的情况下，更精准地捕捉用户当前的兴趣。**此外，DIN模型也适用于其他有丰富行为数据的场景，比如，电商中的个性化推荐，以及当前比较火热的feed流推荐等。

# 代码解读

## 亚马孙数据格式

| reviews_Electronics数据 |                                |
| ----------------------- | ------------------------------ |
| reviewerID              | 评论者id，例如[A2SUAM1J3GNN3B] |
| asin                    | 产品的id，例如[0000013714]     |
| reviewerName            | 评论者昵称                     |
| helpful                 | 评论的有用性评级，例如2/3      |
| reviewText              | 评论文本                       |
| overall                 | 产品的评级                     |
| summary                 | 评论摘要                       |
| unixReviewTime          | 审核时间（unix时间）           |
| reviewTime              | 审核时间（原始）               |

| meta_Electronics 数据 |                    |
| --------------------- | ------------------ |
| asin                  | 产品的ID           |
| title                 | 产品名称           |
| imUrl                 | 产品图片地址       |
| categories            | 产品所属的类别列表 |
| description           | 产品描述           |

> 亚马逊数据集包含产品评论和产品原始数据，用作基准数据集。我们对名为Electronics的子集进行实验，其中包含192,403个用户，63,001个商品，801个类别和1,689,188个样本。 此数据集中的用户行为很丰富，每个用户和商品都有超过5条评论。 **特征**包括goods_id，cate_id，用户评论goods_id_list和cate_id_list。用户的所有行为都是b1，b2，...，bk，... ，bn），**任务是通过利用前k个评论商品来预测第（k + 1）个评论的商品。** 训练数据集是用每个用户的k = 1,2，...，n-2生成的。 **在测试集中，我们预测最后一个给出第一个n - 1评论商品。**

# 参考

[CTR预估之Deep Interest NetWork模型原理详解](https://blog.csdn.net/yz930618/article/details/85003101)

[Deep Interest Network解读](https://www.jianshu.com/p/132da6864d40?utm_campaign=maleskine&utm_content=note&utm_medium=seo_notes&utm_source=recommendation)

