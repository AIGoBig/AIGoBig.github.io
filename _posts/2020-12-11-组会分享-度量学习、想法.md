---
marp: true
theme: gaia
paginate: true
# footer: 'jeremyxu 2020-04-23'
style: |
  section {
      font-size: 25px;
      color: black
  }
backgroundImage: url(images/background_XDU.png)

---
<!-- 
_backgroundImage: url(https://cdn.jsdelivr.net/gh/sunqinghu/PicRepo/img/2020/20201211190830.png)
_class: lead
_paginate: false -->

<style scoped>
section {
    font-size: 30px;
}
</style>

# 组会报告

---
<!-- _class: lead 
_paginate: false -->

<style scoped>
section {
    text-align: center;
    font-size: 30px;
}
</style>

## 目录

1.度量学习介绍

2.相关文献

3.想法思路

4.实验进展

---
<!-- 
_class: lead gaia
_paginate: false
_color: black -->

<style scoped>
section {
    font-size: 30px;
}
</style>

# 度量学习介绍

---
## 概念

度量学习 (Metric Learning) 等同于距离度量学习 (Distance Metric Learning，DML) 和相似度学习,  是人脸识别中常用的机器学习方法, 由Eric Xing在NIPS 2002提出。

度量学习的**对象**通常是**样本特征向量的距离**。

度量学习的**目的**是通过训练和学习，**减小或限制同类样本之间的距离，同时增大不同类别样本之间的距离。**

度量学习分为两种，一种是基于监督学习的，另外一种是基于非监督学习的。

---
## 与经典识别网络的区别 (优势)
- **经典识别网络**存在一个问题：必须提前设定好类别数，例如使用softmax loss的网络。这也就意味着，每增加一个新种类，就要重新定义网络模型，并从头训练一遍。

  > 训练和测试人脸识别分类器的时候经常被提到的Open-set 和Close-set：
  >
  > - close-set，就是所有的测试集都在训练集中出现过。所以预测结果是图片的ID，如果想要测试两张图片是否是同一个，那么就看**这两张图片的预测ID是否一样**即可。
  > - open-set，就是测试的图片并没有在训练集中出现过，那么每张测试图片的预测结果是特征向量，如果想要比较两张图片是否属于同一类别，需要测试**图像特征向量的距离**。
  > 

- 所以，理想的Open-set下就需要度量学习。人脸识别学习到的特征应当在特定的度量空间中，**满足同一类的最大类内距离小于不同类的最小类间距离。**然后再使用**最近邻检索**就可以实现良好的人脸识别和人脸验证性能。因此，Metric Learning作为经典识别网络的替代方案，可以很好地适应某些特定的图像识别场景。
- 然而softmax loss仅仅能够使得特征可分，还不能够使得特征具有可判别性，所以需要对softmax loss进行改造。**一种较好的做法，是丢弃经典神经网络最后的softmax层，改成直接输出一个feature vector，去特征库里面按照Metric Learning寻找最近邻的类别作为匹配项。**

---
## 基本流程：

一般的度量学习包含以下步骤：

- **Encoder编码**模型：用于把原始数据编码为特征向量（重点如何训练模型）
- **相似度判别**算法：将一对特征向量进行相似度比对（重点如何计算相似度，阈值如何设定）
  - 根据不同的任务来自主学习出针对某个特定任务的度量距离函数。通过计算两张图片之间的相似度，使得输入图片被归入到相似度大的图片类别中去。

## 关键问题：

- 网络设计：代表有孪生神经网络（Siamese network）
- hard negative mining：**找出难以区分的样本，更利于训练收敛。**
- pairs weighting/pair-based loss functions：**改进loss函数，促使网络优化， 使具有相同标签的样本在嵌入空间中尽量接近 ，具有不同标签的样本在嵌入空间中尽量远离。**

---

## 有监督度量和无监督度量

**一. 监督学习**

1）LDA Fisher 线性判别

2）Local LDA (Local Linear Discriminative Analysis)

3）RCA 相关成分分析 ( Relevant Component Analysis)

4）LPP 局部保留投影 ( Locality Preserving Projection)

5）LMNN 大间隔最近邻 ( Large-Margin Nearest Neighbors)

6）LLE 局部线性嵌入 (Locally linear embedding)

监督学习的方法应用比较多，包括上一节我们讲到的 **基于CNN的特征提取**都属于监督学习的范畴。

**二. 无监督学习**

   严格说来，**非监督的度量学习（主要是指降维方法）不算真正的度量学习**，我们也把他们列出来，方便读者记忆：

1）主成分分析(Pricipal Components Analysis, PCA)

2）多维尺度变换(Multi-dimensional Scaling, MDS)

3）独立成分分析(Independent components analysis, ICA)

4）拉普拉斯特征映射（Laplacian Eigenmaps）


---
## 有监督度量学习

有监督度量学习算法**利用输入点$x$与目标标签$y$学习一个距离矩阵，** 这个距离矩阵拉近同类别的点（分类问题）或者目标值邻近的点（回归问题）的距离，并使不同类别或目标值相差大的点的互相远离。

![img](https://cdn.jsdelivr.net/gh/sunqinghu/PicRepo/img/2020/20180610151149936.png)

 [度量学习系列（2）：有监督度量学习 -- 程序](https://blog.csdn.net/u013468614/article/details/102846295)

---





---

## Reference

[深度度量学习的这十三年，难道是错付了吗？](https://www.jiqizhixin.com/articles/2020-05-16-5)

[度量学习---综述](https://blog.csdn.net/xys430381_1/article/details/90705421)

[度量学习系列（2）：有监督度量学习 -- 程序](https://blog.csdn.net/u013468614/article/details/102846295)































