# 度量学习介绍

---

## 概念

度量学习

即学习一个度量空间，在该空间中的学习异常高效，这种方法**多用于小样本分类**。直观来看，如果我们的目标是从少量样本图像中学习，那么一个简单的方法就是**对比你想进行分类的图像和已有的样本图像。** 但是，正如你可能想到的那样，在像素空间里进行图像对比的效果并不好。不过，你可以**训练一个 Siamese 网络或在学习的度量空间里进行图像对比。** 与前一个方法类似，元学习通过梯度下降（或者其他神经网络优化器）来进行，而学习者对应对比机制，即在元学习度量空间里对比最近邻。**这些方法用于小样本分类时效果很好**，不过度量学习方法的效果尚未在回归或强化学习等其他元学习领域中验证。

来源： [机器之心](https://www.jiqizhixin.com/articles/2017-07-20-4)

---

度量学习（Metric Learning），也称距离度量学习(Distance Metric Learning，DML) 属于机器学习的一种。  是人脸识别中常用的机器学习方法, 由Eric Xing在NIPS 2002提出。

> 其本质就是相似度的学习，也可以认为距离学习。因为在一定条件下，相似度和距离可以相互转换。比如在空间坐标的两条向量，既可以用余弦相似度的大小，也可以使用欧式距离的远近来衡量相似程度。

度量学习的**对象**通常是**样本特征向量的距离**。

度量学习的**目的**是通过训练和学习，**减小或限制同类样本之间的距离，同时增大不同类别样本之间的距离。**

度量学习分为两种，一种是基于监督学习的，另外一种是基于非监督学习的。

---

## 与经典识别网络的区别 (优势)

- **经典识别网络**存在一个问题：必须提前设定好类别数，例如使用softmax loss的网络。这也就意味着，每增加一个新种类，就要重新定义网络模型，并从头训练一遍。

  > 训练和测试人脸识别分类器的时候经常被提到的Open-set 和Close-set：
  >
  > - close-set，就是所有的测试集都在训练集中出现过。所以预测结果是图片的ID，如果想要测试两张图片是否是同一个，那么就看**这两张图片的预测ID是否一样**即可。
  > - open-set，就是测试的图片并没有在训练集中出现过，那么每张测试图片的预测结果是特征向量，如果想要比较两张图片是否属于同一类别，需要测试**图像特征向量的距离**。

- 所以，理想的Open-set下就需要度量学习。人脸识别学习到的特征应当在特定的度量空间中，**满足同一类的最大类内距离小于不同类的最小类间距离。**然后再使用**最近邻检索**就可以实现良好的人脸识别和人脸验证性能。因此，Metric Learning作为经典识别网络的替代方案，可以很好地适应某些特定的图像识别场景。

- 然而softmax loss仅仅能够使得特征可分，还不能够使得特征具有可判别性，所以需要对softmax loss进行改造。**一种较好的做法，是丢弃经典神经网络最后的softmax层，改成直接输出一个feature vector，去特征库里面按照Metric Learning寻找最近邻的类别作为匹配项。**

---

## 基本流程：

一般的度量学习包含以下步骤：

- **Encoder编码**模型：用于把原始数据编码为特征向量 **（重点如何训练模型）** 
- **相似度判别**算法：将一对特征向量进行相似度比对 **（重点如何计算相似度，阈值如何设定）** 
  - 根据不同的任务来**自主学习出针对某个特定任务的度量距离函数**。通过计算两张图片之间的相似度，使得输入图片被归入到相似度大的图片类别中去。

![bg right:40% w:13cm](/img/in-post/20_07/20160926184002910-20201214195317710.png)

---

## 关键问题：

- 网络设计：代表有孪生神经网络（Siamese network）
- hard negative mining：**找出难以区分的样本，更利于训练收敛。**
- 损失改进：代表有xx-softmax, **改进loss函数，促使网络优化， 使具有相同标签的样本在嵌入空间中尽量接近 ，具有不同标签的样本在嵌入空间中尽量远离。**

---

本文介绍重点是**损失改进派**，是最近发展迅速，应用广泛的方法。

在人脸识别与声纹识别这种度量学习算法中，算法的提高主要体现在损失函数的设计上，**损失函数会对整个网络的优化有着导向性的作用**。可以看到许多常用的损失函数，从传统的softmax loss到cosface, arcface 都有这一定的提高。

无论是SphereFace、CosineFace还是ArcFace的损失函数，都是基于Softmax loss来进行修改的。



|                    |                                                              |
| ------------------ | ------------------------------------------------------------ |
| **Base line**      | **Softmax loss**                                             |
| **各种延伸的算法** | **Triplet loss, center loss**                                |
| **最新算法**       | **A-Softmax Loss(SphereFace), Cosine Margin Loss, Angular Margin Loss, Arcface** |

---

## 有监督度量和无监督度量

**一. 监督学习**

1）LDA Fisher 线性判别

2）Local LDA (Local Linear Discriminative Analysis)

3）RCA 相关成分分析 ( Relevant Component Analysis)

4）LPP 局部保留投影 ( Locality Preserving Projection)

5）LMNN 大间隔最近邻 ( Large-Margin Nearest Neighbors)

6）LLE 局部线性嵌入 (Locally linear embedding)

监督学习的方法应用比较多，包括上一节我们讲到的 **基于CNN的特征提取**都属于监督学习的范畴。

**二. 无监督学习**

   严格说来，**非监督的度量学习（主要是指降维方法）不算真正的度量学习**，我们也把他们列出来，方便读者记忆：

1）主成分分析(Pricipal Components Analysis, PCA)

2）多维尺度变换(Multi-dimensional Scaling, MDS)

3）独立成分分析(Independent components analysis, ICA)

4）拉普拉斯特征映射（Laplacian Eigenmaps）


---

## 有监督度量学习

有监督度量学习算法**利用输入点$x$与目标标签$y$学习一个距离矩阵，** 这个距离矩阵拉近同类别的点（分类问题）或者目标值邻近的点（回归问题）的距离，并使不同类别或目标值相差大的点的互相远离。

![img](/img/in-post/20_07/20180610151149936-7946797.png)

 [度量学习系列（2）：有监督度量学习 -- 程序](https://blog.csdn.net/u013468614/article/details/102846295)

---

## 基本loss概述

### 1. Softmax loss

![](/img/in-post/20_07/20190622174411472-20201214195317257.png)

> 这就是softmax loss函数，${W^T_{j}x_i+b_{j}}$表示全连接层的输出。在计算Loss下降的过程中，我们让${W^T_{j}x_i+b_{j}}$ 的比重变大，从而使得log() 括号内的数更变大来更接近1，就会 log(1) = 0，整个loss就会下降。

---

![w:18cm drop-shadow](/img/in-post/20_07/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h5czQzMDM4MV8x,size_16,color_FFFFFF,t_70-20201214044635795-20201214195317495.png)

> **图如何理解呢？倒数第二层输出不应该是很多维吗？** 形象的理解:当做是一个球体，但是为了可视化方便，把球给压扁了。就成为了二维的图像。（个人理解）
>
> **如何操作？** 应该通过降维方法。
>
> **这样如何完成分类的？** 我们知道，softmax分类时取的是最大那类（argmax），只要目标那一类大于其他类就可以了。反映在图上，每个点与各类中心的距离（W与b决定），距离哪个中心最近就会分成哪一类。

---

可以发现，Softmax loss做分类可以很好完成任务，但是如果进行**相似度比对**就会有比较大的问题（参加[[深度概念\]·Softmax优缺点解析](https://blog.csdn.net/xiaosongshine/article/details/88826715)）

- **L2距离**：L2距离越小，向量相似度越高。可能**同类的特征向量距离（黄色）比不同类的特征向量距离（绿色）更大**

![w:13cm](/img/in-post/20_07/v2-6034febeacba9f5c10a9875e7ba4e573_hd-20201214195317128.jpg)

---

- **cos距离**：夹角越小，cos距离越大，向量相似度越高。**可能同类的特征向量夹角（黄色）比不同类的特征向量夹角（绿色）更大**

![w:13cm](/img/in-post/20_07/v2-21f6b9816a46ee12b624feed740d4ea2_hd-20201214195317112.jpg)

------

总结来说：

1. **Softmax训练的深度特征，会把整个超空间或者超球，按照分类个数进行划分，保证类别是可分的，这一点对多分类任务如MNIST和ImageNet非常合适，因为测试类别必定在训练类别中。**
2. 但Softmax并**不要求类内紧凑和类间分离**，这一点非常不适合人脸识别任务，因为训练集的1W人数，相对测试集整个世界70亿人类来说，非常微不足道，而我们不可能拿到所有人的训练样本，更过分的是，一般我们还要求训练集和测试集不重叠。
3. **所以需要改造Softmax，除了保证可分性外，还要做到特征向量类内尽可能紧凑，类间尽可能分离。**



这种方式只考虑了能否正确分类，却没有考虑类间距离。所以提出了center loss 损失函数。

---

### 2.Center loss

![在这里插入图片描述](/img/in-post/20_07/20190622174504721-20201214195317133.png)
![在这里插入图片描述](/img/in-post/20_07/20190622174546809-20201214195317557.png)
center loss 考虑到不仅仅是分类要对，而且要求类间有一定的距离。上面的公式中 $C_{y_{i}}$表示某一类的中心，$\mathcal{X}_{i}$表示每个人脸的特征值。作者在softmax loss的基础上加入了$L_{C}$，同时使用参数$λ$来控制类内距离，整体的损失函数如下：
![在这里插入图片描述](/img/in-post/20_07/2019062217494518-20201214195317269.png)
![bg right w:16cm drop-shadow](/img/in-post/20_07/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h5czQzMDM4MV8x,size_16,color_FFFFFF,t_70-20201214045052534-20201214195317377.png)

---

### 3. Triplet Loss

![在这里插入图片描述](/img/in-post/20_07/20190622175102498-20201214195317342.png)
三元组损失函数，三元组由Anchor， Negative， Positive这三个组成。从上图可以看到，一开始Anchor离Positive比较远，我们想让Anchor和Positive尽量的靠近（同类距离），Anchor和Negative尽量的远离（类间距离）。
![在这里插入图片描述](/img/in-post/20_07/20190622175146562-20201214195317351.png)
表达式左边为同类距离 ，右边为不同的类之间的距离。**使用梯度下降法优化的过程就是让类内距离不断下降，类间距离不断提升，这样损失函数才能不断地缩小。**

---

#### **triplet网络模型**

https://github.com/SpikeKing/triplet-loss-mnist

Triplet Loss的核心是锚示例、正示例、负示例共享模型，通过模型，将锚示例与正示例聚类，远离负示例。
Triplet Loss Model的结构如下：
输入：三个输入，即锚示例、正示例、负示例，不同示例的结构相同；
模型：一个共享模型，支持替换为任意网络结构；
输出：一个输出，即三个模型输出的拼接。



![w:30cm](/img/in-post/20_07/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h5czQzMDM4MV8x,size_16,color_FFFFFF,t_70-20201214091614709-20201214195317511.png)

---

![](/img/in-post/20_07/R0cHM6Ly9ibG9nLmNzZG4ubmV0L3h5czQzM-7908881-7946797.png)

---

#### 为什么不用softmax？

谷歌的论文FaceNet: A Unified Embedding for Face Recognition and Clustering最早将triplet loss应用到人脸识别中。他们提出了一种实现人脸嵌入和在线triplet挖掘的方法，这部分内容我们将在后面章节介绍。

在监督学习中，我们通常都有一个有限大小的样本类别集合，因此可以使用softmax和交叉熵来训练网络。但是，有些情况下，我们的样本类别集合很大，比如在人脸识别中，标签集很大，而我们的任务仅仅是判断两个未见过的人脸是否来自同一个人。

**Triplet loss就是专为上述任务设计的。它可以帮我们学习一种人脸嵌入，使得同一个人的人脸在嵌入空间中尽量接近，不同人的人脸在嵌入空间中尽量远离。**

---

#### 定义损失

Triplet可以理解为一个三元组，它由三部分组成：

- anchor在这里我们翻译为原点
- positive同类样本点（与原点同类）
- negative异类样本点

针对三元组中的每个元素（样本），训练一个**参数共享或者不共享的网络**，得到三个元素的**特征表达(embedings)**
![bg right w:18cm](/img/in-post/20_07/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h5czQzMDM4MV8x,size_16,color_FFFFFF,t_70-20201214092938052-20201214195317558.png)

---

Triplet loss的目标：

- 使具有相同标签的样本在嵌入空间中尽量接近
- 使具有不同标签的样本在嵌入空间中尽量远离

值得注意的一点是，如果只遵循以上两点，最后嵌入空间中相同类别的样本可能collapse到一个很小的圈子里，即同一类别的样本簇中样本间的距离很小，**不同类别的样本簇之间也会偏小**。因此，我们加入**间隔(margin)** 的概念——跟SVM中的间隔意思差不多。只要不同类别样本簇简单距离大于这个间隔就阔以了。

我们要求，在嵌入空间d中，**三元组(a,p,n)的损失函数**为：

$$L=\max (d(a, p)-d(a, n)+\operatorname{margin}, 0)$$

最小化该L，则**d(a,p)→0, d(a,n)>margin**。

---

#### Triplets挖掘

基于前文定义的Triplet loss，可以将三元组分为一下三个类别：

- easy triplets：可以使loss = 0的三元组，即容易分辨的三元组
- hard triplets：d(a,n)<d(a,p)的三元组，即一定会误识别的三元组
- semi-hard triplets：d(a,p)<d(a,n)<d(a,p)+margin的三元组，即处在模糊区域（关键区域）的三元组
  ![bg right:40% w:13cm  drop-shadow](/img/in-post/20_07/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h5czQzMDM4MV8x,size_16,color_FFFFFF,t_70-20201214094248091-20201214123223361-20201214195317603.png)

图中，a为原点位置，p为同类样本例子，不同颜色表示的区域表示异类样本分布于三元组类别的关系．

显然，中间的Semi-hard negatives样本对我们网络模型的训练至关重要。

---

**上面的几个算法都是比较传统老旧的，下面说一下比较新的算法。**

---

### **4. L-softmax**

前面Softmax loss函数没有考虑类间距离，Center loss函数可以使类内变得紧凑，但没有类间可分，而Triplet loss函数比较耗时，就产生了一下新的算法。

L-softmax函数开始就做了比较精细的改动，从softmax 函数log里面的 $e^{W^T_{y_i}x_i+b_{y_i}}$  转化到$e^{||W_{yi}|| ||x_i||\psi{(\theta_{y_i})}}$。L-softmax函数不仅希望类间距离拉的更大，还能够把**类内距离压缩的更紧凑**。
$$
L_4 = \frac{1}{N}\sum_{i=1}^N L_i = \frac{1}{N}\sum_{i=1}^N -log(\frac{e^{f_{yi}}}{\sum_{j}e^{f_i}})
$$

$$
L_i = -log(\frac{e^{||W_{yi}|| ||x_i||\psi{(\theta_{y_i})}}} {e^{||W_{yi}|| ||x_i||\psi{(\theta_{y_i})}} + \sum_{ j\neq y_i}{e^{||W_j|| ||x_i||cos(\theta_j)}}})
$$

把其中的cosθ改成了cos(mθ)，
$$
\psi(\theta) = \left\{\begin{matrix} \cos (m\theta ), 0\leqslant \theta \leqslant \frac{\pi }{m}& & \\ D(\theta), \frac{\pi}{m}\leqslant \theta \leqslant \pi & & \end{matrix}\right.
$$
m倍θ起到了增加 margin 的效果，让类内距离更加紧凑，同时类间距离变大。m越大类间距离就越大，因为在(0, π)区间cos函数单调递减，m越大 cos(mθ)趋向于0。

![img](/img/in-post/20_07/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI1MDU2MTc=,size_16,color_FFFFFF,t_70-20201214195320411.png)



### 5. SphereFace(A-Softmax)

A-softmax 是在 L-softmax 函数上做了一个很小的修改，A-softmax 在考虑 margin时添加两个限制条件：将权重W归一化 ||W|| = 1，b = 0。**这使得模型的预测仅取决于 W 和 X 之间的角度。**


$$
\LARGE L_5 = -\frac{1}{N}\sum_{i=1}^{N}log( \frac{e^{||x_i||\cos(m\theta_{y_i})}} {e^{||x_i||\cos(m\theta_{y_i})} + \sum_{j \neq y_i}{e^{||x_i||cos(\theta_j)}}})
$$


### 6. CosFace

cosface的loss函数如下：
$$
\LARGE L_6 = -\frac{1}{N} \sum_{i=1}^{N} log( \frac{e^{s(cos(\theta_{yi})-m)}}{e^{s(cos(\theta_{yi})-m)}+ \sum_{j=1, j\neq y_i}^k e^{scos \theta_j}})
$$
上式中，s为超球面的半径，m为margin。



### 7. ArcFace

对比arcface和cosface这两个函数，**发现arcface是直接在角度空间中最大化分类界限，而cosface是在余弦空间中最大化分类界限，这样修改是因为角度距离比余弦距离在对角度的影响更加直接。** 
$$
\LARGE L_7= -\frac{1}{N} \sum_{i=1}^{N} log(\frac{e^{s(cos(\theta_{yi}+m))}}{e^{s(cos(\theta_{yi}+m))}+\sum_{j=1,j\neq y_i}^k e^{scos\theta_j}})
$$
分类的决策边界如下：

![img](/img/in-post/20_07/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI1MDU2MTc=,size_16,color_FFFFFF,t_70-20201214113209962-20201214195317673.png)

 arcface算法流程如下：

![img](/img/in-post/20_07/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTI1MDU2MTc=,size_16,color_FFFFFF,t_70-20201214113209827-20201214195317673.png)

 

### N-pair loss

Sohn, K.: Improved deep metric learning with multi-class n-pair loss objective. In:
NIPS. (2016)
[Improved Deep Metric Learning with Multi-class N-pair Loss Objective论文N-pair loss解读与实现](https://blog.csdn.net/silence2015/article/details/84878692)
pytorch代码：1、https://github.com/ChaofWang/Npair_loss_pytorch/blob/master/Npair_loss.py
2、https://github.com/leeesangwon/PyTorch-Image-Retrieval/blob/public/losses.py
tensorflow代码（多种度量学习loss函数）：https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/contrib/losses/python/metric_learning/metric_loss_ops.py

---

### Angular Loss

[【2017_ICCV】Deep Metric Learning with Angular Loss](https://blog.csdn.net/booyoungxu/article/details/78507346)
tensorflow代码：https://github.com/geonm/tf_angular_loss
pytorch代码：https://github.com/leeesangwon/PyTorch-Image-Retrieval/blob/public/losses.py
[SphereFace论文学习](https://blog.csdn.net/cdknight_happy/article/details/79268613)：该文提到的A-softmax loss就是Angular Loss的源泉

- 提出了Angular Loss，用角度关系作为相似性度量。- 之前的方法主要用距离进行相似性度量，距离度量在尺度变化时比较敏感，并且对于不同的intra-class采用相同的margin也不合适，Angular Loss自带旋转不变和尺度不变。
- 优点：
  - 引入尺度不变，提高了目标对于特征差异的鲁棒性；
  - 增加了三阶几何限制，捕获了triplet triangles的附加局部结构；
  - 收敛更好。

------

### 相关文章列表

[Improved Deep Metric Learning with Multi-class N-pair Loss Objective论文N-pair loss解读与实现](https://blog.csdn.net/silence2015/article/details/84878692)

CVPR2019 [Ranked List Loss for Deep Metric Learning | 论文分享](https://www.jiqizhixin.com/articles/2019-03-12-19)

[距离和相似度度量方法](https://blog.csdn.net/yangdashi888/article/details/82628550)



---

## 可视化

![image-20201214123302743](/img/in-post/20_07/image-20201214123302743-7946797.png)



## Reference

[19_5_度量学习——综述](https://blog.csdn.net/xys430381_1/article/details/90705421)

[度量学习系列（2）：有监督度量学习 -- 程序](https://blog.csdn.net/u013468614/article/details/102846295)

triplet网络模型：https://github.com/SpikeKing/triplet-loss-mnist

## Reference-未用

[20_6_一文看懂人脸识别算法技术发展脉络](https://segmentfault.com/a/1190000022870641)

[20_1_Deep Metric Learning及其形式（附Pytorch代码）](https://zhuanlan.zhihu.com/p/100553403)

[深度度量学习 (metric learning deep metric learning ）度量函数总结](https://blog.csdn.net/u014386899/article/details/100173016)

[深度度量学习的这十三年，难道是错付了吗？](https://www.jiqizhixin.com/articles/2020-05-16-5)



# https://blog.csdn.net/xys430381_1/article/details/90705421)