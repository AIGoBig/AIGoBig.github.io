## API客户

目前只能将之前约定的功能完成，没办法将所有数据测试的，如果还要进行效果优化需要重新评估工作。你看有问题吗，没问题的话我把目前的新版的发你。

我更新了一版，可以将翻译前后内容都输出，错误的处理在新版本了，针对我这边用的测试样例已经没问题了。针对具体的敏感内容配置和指令，你可以通过配置文件来修改。



中间结果保存改好了，每10段会进行一次保存。

另外，给你升级成对文件夹下的docx批量读取生成了哈，目前的逻辑是，如果当前docx已经生成过了，就不会再生成了。目前需要配置"data_files_path": "data/input/word/"和"data_files_out": "data/output/word/"为存储目录就可以。

敏感词也修改了下，所以你用下我最新的配置哈。



### 问题解答

1. Q 目前每个 prompt 都要带“你是一个翻译…”然后才是“待翻译的是…”，这样会不会每次都占用一些 token
2. A 是的，如果在意token长度，所以可以适当调优和删减prompt，降低token占用。
3. Q 模型价格那个算法还不太懂，网页那个“模型价格”那有四个数，然后文档里算法是：提示和补全经过运算算出来一个具体数？和上面截图里的四个数是怎么样的函数关系呢
4. A 费用计算公式：
   1. 按量计费费用 = 分组倍率 × 模型倍率 × （提示token数 + 补全token数 × 补全倍率）/ 500000 （单位：美元），如：
   2. 普通账号：0.8 × 0.25 ×(1000000 + 1000000 × 3)/ 500000 =1.2 
   3. vip账号：0.6 × 0.25 ×(1000000 + 1000000 × 3)/ 500000 =0.9
5. Q 每次prompt的“你是一个翻译...”那段，最长可以有多长？可以把所有的要求都写进去吗，写多了会不会模型抓不到重点？
6. A 目前模型基本都支持8K以上的输入了，可以具体参考每种模型参数。
7. Q 我想带一个字典文件，让模型翻译的时候遇到人名什么的按字典文件里的对应关系翻译，这种怎么实现呢，或者能不能写到prompt里？
8. A 可以，但不建议，因为这样效果不好。如果是字典的方式，需要进行定制开发代码。
9. Q 你们这个接口，有没有对原厂的API做一些加工什么的？我之前用原厂的GLM-4，全拒绝翻译，后来他们客服打电话我说了这个情况，他们说，这应该是你们这边封装或加工了
10. A 接口没有封装加工，可能有模型参数等的不同。如果针对相同模型有较大差异，可以把对比截图给到我们对比看下。
11. Q 如果想节约token，这个描述应该怎么写
12. A 这个只能多调整测试下，可以测试好后再批量跑数据
13. Q prompt中是否有一些可以起强调作用的符号？比如多层括号表强调？这种规定对不同的模型是否都有效
14. A 有的，比如<>等，不过不同模型是不同的
15. Q 我通过你们的中转调用，你们会不会给我的KEY绑定一个也传给模型的用户ID？（因为无ID的话，被拒绝再多次肯定也没事，有ID的话，可能拒绝多了就被封ID，就像我的智谱APP）
16. 不会封ID的，有问题可以联系我们。