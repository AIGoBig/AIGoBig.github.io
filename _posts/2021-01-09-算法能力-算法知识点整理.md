---
layout: post
Comment: true
mathjax: true
author: "Sun"
header-style: text
tags:
  - 算法
catalog: true

---

主要对算法知识点按照深度网络、机器学习、特征工程和竞赛track来进行分类。

# 深度网络(NN)

## 神经网络原理

### 深度网络都有哪些？

- VGG
- Resnet
- Inception V1-v3
- Densnet
- ResnXt
- SENet
- NAS
- 下面几个是轻量化模型：
  - MobileNet V1-V2
  - mobileNet V3（novel）：https://arxiv.org/pdf/1905.02244.pdf
  - Xception
  - shufflenet V1-V2
  - squeezenet
- group convolution
- SEResNet，SEResNeXt
- NAS
- EfficientNet

### CNN的三大优势

- 局部连接

  - 更少的存储空间，还提高了统计效率
  - 深层的网络间接的将整个或者大部分图像进行了全连接。

- 权值共享

  - 减少参数数量

- 平移不变性

  - 不去关心特征出现的位置而只是关心它是否出现

### CNN的结构

- 输入层
- 卷积层

  - 卷积核，提取图像特征

- 激活函数

  - 增强网络的非线性表达能力
  - 为防止梯度弥散的发生 （待研究）

- 池化层

  - 降维，减少数据量

- 输出层

  - 将特征映射到标记空间进行了预测

- 目标函数(损失函数)

  - 计算预测值和实际值的误差

### ResNet为什么有效

参考：[为什么ResNet和DenseNet可以这么深？一文详解残差块为何有助于解决梯度弥散问题。](https://blog.csdn.net/nini_coded/article/details/79582902)

- 从梯度弥散、网络退化角度看

	- **梯度消失/爆炸**已经通过 normalized 、initialization 等方式得到缓解。残差结构是为了解决**网络退化**的问题提出的，跨层输入相当于一个恒等映射，中间层只需拟合残差，因此层的加入不会使效果变差
	- 在网络上堆叠这样的结构，**就算梯度消失，我什么也学不到，我至少把原来的样子恒等映射了过去**，相当于在浅层网络上堆叠了“**复制层**”，这样**至少不会比浅层网络差**。万一我不小心学到了什么，那就赚大了，由于我经常恒等映射，所以我学习到东西的概率很大。
- 从**梯度反向传播的角度**解释
  - 即过于深的网络在反传时容易发生梯度弥散，一旦某一步开始导数小于1，此后**继续反传**，传到前面时，用float32位数字已经无法表示梯度的变化了，相当于梯度没有改变，也就是浅层的网络学不到东西了。**这是网络太深反而效果下降的原因**。
  - 加入ResNet中的shortcut结构之后，在**反传时，每两个block之间不仅传递了梯度，还加上了求导之前的梯度**，这相当于把每一个block中向前传递的梯度人为加大了，也就会**减小梯度弥散的可能性**。
- 解决**欠拟合**问题角度解释(待研究)

  - 在正向卷积时，对每一层做卷积其实只提取了图像的一部分信息，这样一来，越到深层，原始图像信息的丢失越严重，而仅仅是对原始图像中的一小部分特征做提取。 这显然会发生类似欠拟合的现象。
  加入shortcut结构，相当于在**每个block中又加入了上一层图像的全部信息，一定程度上保留了更多的原始信息。**
  - 由于每做一次卷积（包括对应的激活操作）都会浪费掉一些信息：比如卷积核参数的随机性（盲目性）、激活函数的抑制作用等等。这时，**ResNet中的shortcut相当于把以前处理过的信息直接再拿到现在一并处理，起到了减损的效果。**
- 模型集成角度解释（加入shortcut后**相当于一个ensemble模型**）

	- **输出的结果是前面各个block及其组合一起做的一个投票选出的结果**。即可以把ResNet网络看成是多个子网络并行，从实验中看，真实起作用的路径长度并不深，主要走是中等深度的网络。简单来说，就是**做了不同层次上的特征组合。**
- 特征具有层次性的角度解释

	- **回到网络结构上面，浅层网络提取的是简单的特征**，而简单和复杂的特征适用于不同的样本，没有shortcut时，对所有样本的分类都是利用最复杂的特征判断，费时费力；**加入shortcut后，相当于保留了一些简单的特征用于判断，变得省时。这一观点主要解释了为什么ResNet网络能够更快收敛。**

### Dense-Net

与ResNet想法类似的DenseNet，是**把前面每一个block输出的梯度都skip connection到后面各个block的输出**，同时在同一层增加了类似Inception的选择式结构（待研究）？？？？？，介绍了参数，进一步提升了效果，该方法论文还获得了2017CVPR best paper。

![这里写图片描述](/img/in-post/20_07/70.jpeg)

### SE-ResNet

参考：[SENet（Squeeze-and-Excitation Networks）算法笔记](https://blog.csdn.net/u014380165/article/details/78006626)

论文：Squeeze-and-Excitation Networks
论文链接：https://arxiv.org/abs/1709.01507
代码地址：https://github.com/hujie-frank/SENet
PyTorch代码地址：https://github.com/miraclewkf/SENet-PyTorch

- **创新点**

  - 卷积操作融合了空间和特征通道信息。大量工作研究了空间部分，而结构重点关注**特征通道的关系**，并提出了Squeeze-and-Excitation(SE) block，对通道间的依赖关系进行建模，自适应校准通道方面的特征响应。
  - SE block并不是一个完整的网络结构，而是一个子结构，可以嵌到其他分类或检测模型中。

- **核心思想**

  - 在于通过网络**根据loss去学习特征权重，使得有效的feature map权重大**，无效或效果小的feature map权重小的方式训练模型达到更好的结果。(感觉有点类似通道attention（🚩待研究）)

- **SE block**
  ![1558429951926](/img/in-post/20_07/1519578-20190521200354163-230761194.png)

  > $𝐹_{𝑡𝑟}$表示transformation，在文中就是一系列标准的卷积操作而已；
  >
  > $𝐹_{𝑠𝑞}$表示squeeze，**产生通道描述**； （🚩待研究）
  >
  > $𝐹_{𝑒𝑥}$表示excitation，通过参数𝑊来**建模通道的重要性**；
  >
  > $𝐹_{𝑠𝑐𝑎𝑙𝑒}$表示reweight，将excitation输出的权重逐乘以先前特征，完成特征重标定。

  - squeeze：
    ![这里写图片描述](/img/in-post/20_07/SouthEast.jpeg)
    - 公式非常简单，就是一个global average pooling。
    - 这一步的结果相当于表明该层C个feature map的数值分布情况，或者叫全局信息。
  - Excitation
    ![这里写图片描述](/img/in-post/20_07/SouthEast-20210110002122772.jpeg)
    - 直接看最后一个等号，前面squeeze得到的结果是z，这里先用W1乘以z，就是一个全连接层操作，**W1的维度是C/r \* C，这个r是一个缩放参数，在文中取的是16，这个参数的目的是为了减少channel个数从而降低计算量**。又因为z的维度是1\*1\*C，所以W1z的结果就是1\*1\*C；然后再经过一个ReLU层，输出的维度不变；然后再和W2相乘，和W2相乘也是一个全连接层的过程，**W2的维度是C\*C/r**，因此**输出的维度就是1\*1\*C**；最后再经过sigmoid函数，得到s。
    - 也就是说最后得到的这个s的维度是1\*1\*C，C表示channel数目。**这个s其实是本文的核心，它是用来刻画tensor U中C个feature map的权重。而且这个权重是通过前面这些全连接层和非线性层学习得到的，因此可以end-to-end训练。这两个全连接层的作用就是融合各通道的feature map信息，因为前面的squeeze都是在某个channel的feature map里面操作。**
  - 在得到s之后，就可以对原来的tensor U操作了，就是下面的公式4。也很简单，就是channel-wise multiplication
    ![这里写图片描述](/img/in-post/20_07/SouthEast-20210110003108591.jpeg)
  - 

- **SE-ResNet Module**

  - Figure3是在ResNet中添加SE block的情况。
    <img src="/img/in-post/20_07/1519578-20190521200353846-413277730-20210109185335768.png" alt="1558430934954" style="zoom:80%;" />



### **EfficientNet**

- 思想：
  - 对网络的扩展可以通过**增加网络层数**（depth，比如从 ResNet (He et al.)从resnet18到resnet200 ）, 
  - 也可以通过**增加宽度**，比如WideResNet (Zagoruyko & Komodakis, 2016)和MobileNets (Howard et al., 2017) 
  - 可以**扩大网络的深度 (#channels), **
  - 还有就是**更大的输入图像尺寸(resolution)**也可以帮助提高精度。 （🚩待研究）
- 创新点：
  - **复合模型扩张方法**
  - **神经结构搜索技术**
- 结构：

![img](/img/in-post/20_07/v2-fcbff6e21eb9e7f9cce94c3bd935b84a_720w.jpg)

> 如下图所示: (a)是基本模型，（b）是增加宽度，（c）是增加深度，（d）是增大输入图像分辨率，（d）是EfficientNet，它从三个维度均扩大了，但是扩大多少，就是通过作者提出来的**复合模型扩张方法**结合**神经结构搜索技术**获得的。

## 原理性知识

### 解决过拟合的方法有哪些

- 数据增强
- 模型集成

  - Dropout

    - 相当于每次都在训练不同结构的神经网络
    - 类比bagging，可被认为是一种大规模深度神经网络的模型集成方法
    - 轻量级的bagging集成近似

- 参数正则化（regularization）
- **批量归一化（Batch Normalization）**
  - NN本质是学习数据分布，有两种分布不同：
    训练集和测试集数据分布不同，降低泛化能力。
    随着网络训练，隐层网络参数变化会使网络在每次迭代拟合不同的分布，增大复杂度且易过拟合
  - 数学原理：（x-均值）/ 标准差

### 解决小样本问题的方法有哪些

- 数据增强
- 迁移学习
- 无监督、半监督
- GAN网络
- 网络优化

  - 考虑**样本相关性**（待研究）
  - 多使用残差学习和**特征融合**

### 样本不均衡（长尾效应）的解决方法

某类数据不均衡（某一标签数量太多，其余标签数量太少）的问题，在机器学习中被称为**“长尾问题”**。

这个问题导致，数据集中（尤其是大型数据集）样本数量少的物体，**泛化效果**会非常差。

![img](/img/in-post/20_07/v2-4eb62875ea6a629b3772ae2ec35bc37d_720w.jpg)

方法：

1. **重采样** （re-sampling）：分为对少样本的**过采样**、及多样本的**欠采样**。但这2种方法，都有欠缺：过采样容易发生少样本过拟合，无法学习更鲁棒、易泛化的特征，在不平衡数据上表现较差；欠采样会造成多样本严重信息损失，导致发生欠拟合。
2. **数据合成** （synthetic samples）：**生成和少样本相似的新数据**。以SMOTE方法为例，对于任意选取的少类样本，它用K近邻选取相似样本，并通过对样本线性插值得到新样本。这里与mixup方法相似，因此，也有非均衡的mixup版本出现。

3. **重加权** （re-weighting）：为不同类别（甚至不同样本）分配不同的权重。其中，权重可以自适应。这一方法诞生出很多变种，如对类别数目的倒数进行加权、对“有效”样本数加权、对样本数优化分类间距的损失加权等等。

4. **迁移学习** （transfer learning）：对多类和少类样本**分别建模**，将学到的多类样本信息/表示/知识迁移给少类别使用。
   ![img](https://pic3.zhimg.com/80/v2-623aef46d94f448786ff163b15635872_720w.jpg)
5. **度量学习** （metric learning）：希望能**学到更好的嵌入**，以对少类附近的边界/边缘更好地建模。
6. **元学习/域自适应** （meta learning/domain adaptation）：分别对头、尾部数据进行不同处理，自适应地学习如何重加权，或是规划成域自适应问题。
   ![img](/img/in-post/20_07/v2-0303f1faccc24c84435a5070c1b55bdf_720w.jpg)
7. **解耦特征和分类器** （decoupling representation & classifier）：研究发现，**将特征学习和分类器学习解耦**、将不平衡学习分为两个阶段，并在特征学习阶段正常采样、在分类器学习阶段平衡采样，可以带来更好的长尾学习效果。这是目前最优的长尾分类算法。（🚩待研究）

但这些，在样本极端失衡的情况下也没法用，如果真的只有几个样本，模型的性能差异就无法避免。所以可以考虑如下 的自监督预训练。

### 从半监督，到自监督预训练

[数据集样本有10万，结果80%都是猫？如何解决“数据类别不均衡”丨NeurIPS 2020](https://www.zhihu.com/column/p/344446850)

作者们先对**半监督**下的不均衡学习进行了实验。

实验证明，利用无标记数据的半监督学习，能显著提高分类结果。

从图中可以看出，未标记数据，有助于建模更清晰的类边界，促成更好的类间分离。



![img](/img/in-post/20_07/v2-af61a1a995736837680ff7bc6ae6ecd7_720w.jpg)



这是因为，尾类样本所处区域数据密度低，在学习过程中，模型不能很好地对低密度区域进行建模，导致泛化性差。

而无标记数据，能有效提高低密度区域样本量，使得模型能对边界进行更好的建模。

然而，在一些很难利用半监督学习的极端情况下，仍然需要自监督学习出场。

这是因为，一旦自监督产生良好初始化，网络就可以从预训练任务中受益，学习到更通用的表示形式。

正常预训练的决策边界，很大程度上会被头类样本改变，导致尾类样本大量“泄漏”，无法很好地泛化。

而采用自监督预训练的话，学习到的样本保持清晰的分离效果，且能减少尾类样本泄漏。



![img](/img/in-post/20_07/v2-0f838dd903aa45f367fe0771aaca43bf_720w.jpg)



也就是说，为了利用自监督克服标签偏见，在长尾学习的第一阶段，需要先放弃标签信息，进行**自监督预训练**。

此阶段后，可以使用**任何标准训练方法**，训练得到最终模型。（例如此前所用的迁移学习、重加权、域自适应……）

这样，就能更好地解决长尾问题。

### BN（Batch Normalization）层的原理

BN层的**本质**：`γ`和`β`是需要学习的参数，本质是利用优化来改变方差大小和均值的位置。

> ![img](/img/in-post/20_07/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIxOTk3NjI1,size_16,color_FFFFFF,t_70.png)

### BN层的作用

- 加快**训练速度**增大学习率（可以保证每一层的**输入分布稳定**，这可以使训练加速）
- 减小**梯度消失和梯度爆炸**
- 控制**过拟合**，可以少用或者不用dropout和正则
- **使网络对初始权重不敏感**

### 网络优化方法

- 正则化

	- 防止神经网络的过度拟合，需要对代价函数改进，即加入正则化项
		![image-20210109224137602](/img/in-post/20_07/image-20210109224137602.png)
	- **第一项是均方误差，第二项是正则化**，即权重衰减项，λ对两项的重要性进行控制。
- **动量因子**的权值调节方法
![image-20210109224336007](/img/in-post/20_07/image-20210109224336007.png)
	- 其中ｗ指代的是要更新的参数，ｚ表示迭代的次数，v表示动量，η为动量前的系数，J同前面的代价函数。

### 1X1卷积作用（🚩待研究）

### GAP层的解释

+ 原因
  + 因为全连接层参数最多，所以现在的趋势是尽量**避免全连接**，近期的大部分论文**FC多用全局平均池化层（GAP，Global Average Pooling）的方法代替。**
+ 思想
  + **用 feature map 直接表示属于某个类的 confidence map**，比如有10个类，就在**最后输出10个 feature map**，每个feature map中的值加起来求平均值，这十个数字就是对应的概率或者叫置信度。然后把得到的这些平均值直接作为属于某个类别的 confidence value，**再输入softmax中分类**， 更重要的是实验效果并不比用 FC 差。
  + 主要是从模型压缩的应用中得到的灵感。经过实验加入Gap层的效果没有下降甚至有提升, 我们分析后者的优势是：
    + 1.因为FC的参数众多，这么做就**减少了参数的数量**（在最近比较火的**模型压缩**中，这个优势可以很好的压缩模型的大小）。
    + 2.因为减少了参数的数量，可以很好的**减轻过拟合**的发生。恰恰在小样本的情况下是非常容易过拟合的. 

### **如何解决梯度消失和梯度膨胀？**

（1）梯度消失：

根据链式法则，如果每一层神经元对上一层的输出的偏导乘上权重结果都小于1的话，那么即使这个结果是0.99，在经过足够多层传播之后，误差对输入层的偏导会趋于0。

可以采用ReLU激活函数有效的解决梯度消失的情况。

（2）梯度膨胀：

根据链式法则，如果每一层神经元对上一层的输出的偏导乘上权重结果都大于1的话，在经过足够多层传播之后，误差对输入层的偏导会趋于无穷大。

可以通过激活函数来解决。

### **了解正则化么？**

正则化是针对**过拟合**而提出的，以为在求解模型最优的是一般优化最小的经验风险，现在在该经验风险上加入模型复杂度这一项（正则化项是模型参数向量的范数），并使用一个**rate比率来权衡模型复杂度与以往经验风险的权重**，如果模型复杂度越高，结构化的经验风险会越大，现在的目标就变为了结构经验风险的最优化，**可以防止模型训练过度复杂**，有效的降低过拟合的风险。

奥卡姆剃刀原理，能够很好的解释已知数据并且十分简单才是最好的模型。

### **协方差和相关性有什么区别？**

相关性是协方差的标准化格式。协方差本身很难做比较。例如：如果我们计算工资（$）和年龄（岁）的协方差，因为这两个变量有不同的度量，所以我们会得到不能做比较的不同的协方差。为了解决这个问题，我们计算相关性来得到一个介于-1和1之间的值，就可以忽略它们各自不同的度量。



# 机器学习

## 特征工程相关

### 如何做特征组合

- 特征组合的思想很简单，**通过将单独的特征进行组合（相乘或求笛卡尔积）而形成的合成特征。**比如属性A有三个特征，属性B有两个特征，笛卡尔积后就有六个组合特征，**然后用one hot 或其他embedding方式给新的特征编码**。

### **L1和L2正则先验分别服从什么分布 ？**

面试中遇到的，L1和L2正则先验分别服从什么分布，L1是拉普拉斯分布，L2是高斯分布。

## 模型总览

### **13.谈谈判别式模型和生成式模型？**

判别方法：由数据直接学习决策函数 Y = f（X），或者由条件分布概率 P（Y|X）作为预测模型，即判别模型。

生成方法：由数据学习联合概率密度分布函数 P（X,Y）,然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型。

由生成模型可以得到判别模型，但由判别模型得不到生成模型。

常见的判别模型有：K近邻、SVM、决策树、感知机、线性判别分析（LDA）、线性回归、传统的神经网络、逻辑斯蒂回归、boosting、条件随机场

常见的生成模型有：朴素贝叶斯、隐马尔可夫模型、高斯混合模型、文档主题生成模型（LDA）、限制玻尔兹曼机

## 支持向量机模型

### SVM、SVR、SVC区别

- SVM=Support Vector Machine 是支持向量
- SVC=Support Vector Classification就是支持向量机用于**分类**，
- SVR=Support Vector Regression. 就是支持向量机用于回归分析

> 算法（python-sklearn）-- SVM的几种模型
>
> - svm.LinearSVC Linear Support Vector Classification.
> - svm.LinearSVR Linear Support Vector Regression.
> - svm.NuSVC Nu-Support Vector Classification.
> - svm.NuSVR Nu Support Vector Regression.
> - svm.OneClassSVM Unsupervised Outlier Detection.
> - svm.SVC C-Support Vector Classification.
>
>   - sklearn系列之 sklearn.svm.SVC详解
> - svm.SVR Epsilon-Support Vector Regression.

### **请简要介绍下SVM。**

SVM，全称是support vector machine，中文名叫支持向量机。SVM是一个**面向数据**的分类算法，它的**目标**是为确定一个**分类超平面**，从而将不同的数据分隔开。

### **在k-means或kNN，为什么用欧氏距离来计算最近邻之间的距离而不用曼哈顿距离？**（🚩待研究）

曼哈顿距离只计算水平或垂直距离，**有维度的限制**。另一方面，欧氏距离可用于任何空间的距离计算问题。因为，数据点可以存在于任何空间，欧氏距离是更可行的选择。例如：想象一下国际象棋棋盘，象或车所做的移动是由曼哈顿距离计算的，因为它们是在各自的水平和垂直方向做的运动。



## 线性模型

### **岭回归模型(Ridge Regression)**:

- 就是对于一个线性模型，在原来的损失函数加入参数的*l2*范数的惩罚项, 限制参数

## 逻辑回归（LR）

考察点：把LR从头到脚都给讲一遍。建模，现场数学推导，每种解法的原理，正则化，LR和maxent模型啥关系，LR为啥比线性回归好。有不少会背答案的人，问逻辑细节就糊涂了。原理都会? 那就问工程，并行化怎么做，有几种并行化方式，读过哪些开源的实现。还会，那就准备收了吧，顺便逼问LR模型发展历史。

### **LR和SVM的联系与区别？**

联系：

1、LR和SVM都可以处理**分类**问题，且一般都用于处理线性二分类问题（在改进的情况下可以处理多分类问题） 

2、两个方法都可以增加不同的**正则化项**，如L1、L2等等。所以在很多实验中，两种算法的结果是很接近的。

区别：

**1、LR是参数模型，SVM是非参数模型。**

2、从目标函数来看，区别在于逻辑回归采用的是**Logistical Loss**，SVM采用的是**hinge loss**.这两个损失函数的目的都是增加对分类影响较大的数据点的权重，减少与分类关系较小的数据点的权重。

3、SVM的处理方法是只考虑Support Vectors，也就是和**分类最相关的少数点**，去学习分类器。而逻辑回归通过**非线性映射**，大大减小了离分类平面较远的点的权重，相对提升了与分类最相关的数据点的权重。

4、逻辑回归相对来说模型更简单，好理解，特别是大规模线性分类时比较方便。而SVM的理解和优化相对来说复杂一些，SVM转化为对偶问题后,分类只需要计算与少数几个支持向量的距离,这个在进行复杂核函数计算时优势很明显,能够大大简化模型和计算。

5、Logic 能做的 SVM能做，但可能在准确率上有问题，SVM能做的Logic有的做不了。

### **LR与线性回归的区别与联系？**

个人感觉逻辑回归和线性回归首先都是广义的线性回归， 

其次经典线性模型的优化目标函数是最小二乘，而逻辑回归则是**似然函数**， 

另外线性回归在整个实数域范围内进行预测，敏感度一致，而分类范围，需要在[0,1]。逻辑回归就是一种减小预测范围，将预测值限定为[0,1]间的一种回归模型，因而对于这类问题来说，逻辑回归的鲁棒性比线性回归的要好。

@乖乖癞皮狗：逻辑回归的模型本质上是一个线性回归模型，逻辑回归都是以线性回归为理论支持的。但线性回归模型无法做到sigmoid的非线性形式，sigmoid可以轻松处理0/1分类问题。



## 决策树模型

### 决策树的灵魂

- 即依靠某种指标进行树的分裂达到分类/回归的目的，总是希望纯度越高越好。

### 决策树量化分类效果的方法有哪些

- 信息增益（ID3）

- 信息增益率（C4.5）
- 基尼系数（CART）

### 信息增益（ID3）的理解

- ID3算法的**核心思想**：以信息增益度量属性选择，选择分裂后**信息增益最大**的属性进行分裂。

- 为了精确地定义信息增益，我们先定义信息论中广泛使用的一个**度量标准**称为熵（entropy）

  - 它**刻画了**任意样例集的纯度（purity）。

  - 给定包含关于某个目标概念的正反样例的样例集S，那么S相对这个布尔型分类的熵为：

    <img src="/img/in-post/20_07/image-20210109214727229.png" alt="image-20210109214727229" style="zoom:67%;" />

    <img src="/img/in-post/20_07/image-20210109224025591.png" alt="image-20210109224025591" style="zoom:67%;" />

    其中，p+为正样本概率，p-为负样本概率。

### 决策树的类型

- **分类树**分析是指预测结果是数据所属的类（比如某个电影去看还是不看）
- **回归树**分析是指预测结果可以被认为是实数（例如房屋的价格，或患者在医院中的逗留时间）
- **分类回归树**（CART，Classification And Regression Tree）分析是用于指代上述两种树的总称
- 分类的目标是根据已知样本的某些特征，判断一个新的样本属于哪种已知的样本类，它的结果是**离散值**。而回归的结果是**连续的值**。当然，**本质是一样的，都是特征（feature）到结果/标签（label）之间的映射。**

## 朴素贝叶斯

### **20.为什么朴素贝叶斯如此“朴素”？**

因为它假定所有的特征在数据集中的作用是同样重要和独立的。正如我们所知，这个假设在现实世界中是很不真实的，因此，说朴素贝叶斯真的很“朴素”。



## 集成学习模型

### 集成学习的定义

- 集成学习是指**用某种策略将多个分类器预测的结果集成起来**，作为最终的预测结果

### 集成学习的分类

- Boosting方法（串行，分类器互相依赖）

- bagging方法（可并行，分类器无依赖）


### Boosting方法的思想和作用

- **基本思想：**
  - 训练时，将基分类器层层叠加，每一层训练时对**前一层错分样本给予更高的权重**，分类**错误率低的基分类器给予更高的权重**。
  - 测试时，根据各层分类器的**结果加权**得到最终结果。
- **主要作用**：
  - 减少集成分类器的**偏差**（基分类器层层叠加）

### Boosting方法的例子

1. AdaBoost(自适应增强)

   - 基本思想

     - **前一个分类器**分错/分对的样本的权值会得到加强/降低，**加权后的全体样本再次被用来训练下一个基本分类器**

2. GBDT(梯度提升决策树)

   - 基本思想

     - GBDT的**每一次计算都为了减少上一次的残差**，进而在负梯度的方向上建立一个新的模型
     - 根据**当前模型损失函数的负梯度信息**来训练新加入的弱分类器，然后把训练好的弱分类器以累加的形式结合到现有模型里

   - 例子——XGBoost

     - 目标函数

       - 目标函数分为两个部分：**误差函数**(logistic损失函数、平方损失函数)和**正则化项（**定义模型的复杂度）
       - 将目标函数化简之后，目标函数只依赖于一阶导数g和二阶导数h
       - 将目标函数和正则化项结合化简，对w进行求导，求出最优w，代入目标函数中

### bagging方法的思想和作用

- **基本思想**
  - 将训练集分为若干子集，分别训练各个基分类器
  - 测试时，每个基分类器单独做出判断，通过投票方式做出最终决策

- 作用
  - 减少集成分类器的**方差**（基分类器并行，根据统计学）（待研究）

### **bagging方法的例子**

- 随机森林

### XGBoost问题

- 与GBDT不同之处？

  - 用泰勒展开近似目标函数
- XGBoost为什么使用泰勒二阶展开？为什么用二阶信息不用一阶？
- XGBoost在什么地方做的剪枝，怎么做的？
- XGBoost如何分布式？特征分布式和数据分布式？ 各有什么存在的问题？
- XGBoost里处理缺失值的方法？
- XGBoost有那些优化？
- xgboost对预测模型特征重要性排序的原理？
- XGBoost如何寻找最优特征？是又放回还是无放回的呢？
- GBDT和XGBoost的区别是什么？
- lightgbm和xgboost有什么区别？他们的loss一样么？ 算法层面有什么区别？

### **请问GBDT和XGBoost的区别是什么？**

XGBoost类似于GBDT的优化版，不论是精度还是效率上都有了提升。与GBDT相比，具体的优点有： 

- 损失函数是用泰勒展式**二项逼近**，而不是像GBDT里的就是一阶导数；（🚩待研究）
- 对树的结构进行了**正则化约束**，防止模型过度复杂，降低了过拟合的可能性；
- 节点**分裂的方式**不同，GBDT是用的基尼系数，XGBoost是经过优化推导后的。（🚩待研究）

### **为什么XGBoost要用泰勒展开，优势在哪里？**

XGBoost使用了一阶和二阶偏导, 二阶导数有利于**梯度下降的更快更准**. 使用泰勒展开取得二阶倒数形式, 可以在不选定损失函数具体形式的情况下用于算法优化分析.本质上也就把损失函数的选取和模型算法优化/参数选择分开了. 这种去耦合增加了XGBoost的适用性。



### **LightGBM**

​    LightGBM 是一个**梯度 boosting 框架**，使用**基于学习算法的决策树**。它可以说是分布式的，高效的，有以下优势：更快的训练效率、低内存使用、更高的准确率、支持并行化学习、可处理大规模数据。

## 计算智能方法

### 启发式搜索算法总结

> 启发式搜索算法蕴含着许多人生哲学，它虽不是数学方法，其思想更类似于人类解决问题的思想和一些人生中总结的道理，值得好好体会。最后用网上一段描述各种搜索算法的例子来作为总结：
>
> 为了找出地球上最高的山，一群有志气的兔子们开始想办法。
> （1）兔子朝着比现在高的地方跳去。他们找到了不远处的最高山峰。但是这座山不一定是珠穆朗玛峰。这就是爬山法，它不能保证局部最优值就是全局最优值。
> （2）兔子喝醉了。他随机地跳了很长时间。这期间，它可能走向高处，也可能踏入平地。但是，他渐渐清醒了并朝他踏过的最高方向跳去。这就是模拟退火。
> （3）兔子们知道一个兔的力量是渺小的。他们互相转告着，哪里的山已经找过，并且找过的每一座山他们都留下一只兔子做记号。他们制定了下一步去哪里寻找的策略。这就是禁忌搜索。
> （4）兔子们吃了失忆药片，并被发射到太空，然后随机落到了地球上的某些地方。他们不知道自己的使命是什么。但是，如果你过几年就杀死一部分海拔低的兔子，多产的兔子们自己就会找到珠穆朗玛峰。这就是遗传算法。

# 项目、比赛track解释

## 神经网络

### TTA:

- 就是在测试的时候有一个transform，然后训练的时候使用多个transform，然后得到多个结果，然后让去平均值
- 增加鲁棒性,防止过拟合,避免原始图像显示的区域可能缺少某些特征,
- 包括**不同区域裁剪**和**更改缩放程度**等,提高了结果的稳定性和精准度.

### **标签平滑:**

- 使用原因:
  - 0/1这种 binary 或者说“hard”的答案, 容易导致网络对自己的预测过于自信,导致过拟合
  - 实际上类似的很多大型训练数据集中往往就会有错误标签, 要求网络对正确答案具有一定的怀疑能力, 以减少一定程度上围绕错误答案的极端情况下的建模。
- 使用组归一化（GroupNormalization）代替批量归一化（batch_normalization）
  - 解决当Batch_size过小导致的准确率下降

### **余弦退火**

- 在采用批次随机梯度下降算法时，神经网络应该越来越接近Loss值的全局最小值。当它逐渐接近这个最小值时，学习率应该变得更小来使得模型不会超调且尽可能接近这一点。余弦退火（Cosine annealing）利用余弦函数来降低学习率，进而解决这个问题，如下图所示
- 余弦退火方法的目的在于**逃离当前局部最优点**，寻找新的局部最优点。在每个周期计算完成后，保存不同局部最优点的模型参数。

<img src="/img/in-post/20_07/cosine_annealing_restarts.png" alt="img" style="zoom:50%;" />

# 参考

## 深度网络参考

[【计算机视觉算法岗面经】“吐血”整理：2019秋招资料](https://blog.csdn.net/liuxiao214/article/details/83043170)

[【计算机视觉算法岗面经】“吐血”整理：2019秋招面经](https://blog.csdn.net/liuxiao214/article/details/83043197)

[图像分类丨ILSVRC历届冠军网络「从AlexNet到SENet」](https://blog.csdn.net/woshicver/article/details/105140874)

## 面经（待看）

[深度学习分类模型面试题-面经（一）](https://blog.csdn.net/qq_21997625/article/details/105977807)

[腾讯NLP算法岗面经（offer已拿）](https://zhuanlan.zhihu.com/p/117450353)

[干货满满！分享 BAT 机器学习面试200题！](https://mp.weixin.qq.com/s/LmreEN0BaqDHp5wsClNP5Q)









