

# 论文内容

**20_TGRS_MDL4OW_Few-Shot Hyperspectral Image Classification With Unknown Classes Using Multitask Deep Learning**

该论文针对未知类别的小样本高光谱图像分类问题，首次提出一种新颖的**多任务深度卷积网络分类方法。**

`【代码链接】`https://sjliu.me/MDL4OW

**Few shot**

**Unknown classes**

**Multi-task**

## 提出原因

现有的高光谱图像分类方法都**假设和预定义图像分类系统是封闭且完整的**，并在不可见的数据中**没有未知的或新的图像类别**。然而，这个假设对于现实世界来说可能过于严格，在**构建分类系统时，通常会忽略新的类别**。分类系统的封闭性会迫使模型在给定新样本的情况下指定标签，*并可能导致对已知样本的标签(如作物面积)的覆盖。*为了解决这个问题，本文提出一种**多任务深度学习方法，该方法可以在未知类别可能存在的开放世界(MDL4OW)中同时进行分类和重构。**

**将重构数据与原始数据进行比较;且未被重构的数据被认为是未知的，**并且由于缺少分类标签，这些重构数据在潜在特征中没有被很好地表示，故需要定义一个**阈值**来区分未知类别和已知类别；基于此，**本文提出了两种基于极值理论的策略，分别用于少样本和多样本学习场景**。

该方法在真实高光谱图像上的测试结果获得了最优的结果，如在萨利纳斯数据的测试结果中使分类的整体精度提高了4.94%。**通过考虑开放世界中未知类别的存在，该方法实现了在小样本背景下的更精确的高光谱图像分类。**

## 本文主要贡献如下

1. 该论文针对未知类别的小样本高光谱图像分类问题，首次提出一种新颖的**多任务深度卷积网络分类方法 — MDL4OW**。该方法能够**识别未知小样本图像类别，显著提高高光谱图像分类精度；** 
2. 本文提出的方法使用**统计模型极值理论来估计所有数据的未知分数**，而不是使用基于质心的方法以分类的方式来估计未知分数。因此该方法在小样本高光谱图像分类方面优于现有的开放集图像分类方法； 
3. 本文针对未知类别的高光谱图像分类精度问题，提出了一种新的评价指标—映射误差，这种度量指标对不平衡分类特别敏感，非常适用于高光谱图像分类问题。

# 原理

## 网络结构

<img src="file:///img/in-post/20_07/image-20201109214401498.png?lastModify=1612961813" alt="image-20201109214401498" style="zoom:50%;" />

![image-20201109215304855](file:///img/in-post/20_07/image-20201109215304855.png?lastModify=1612961813)

> 上半部分分为编码部分和分类部分，和常用HSI分类网络相同。
>
> 下半部分主要是反卷积网络，为解码器，重建图像，可以用来判断是不是已知类别



<img src="file:///img/in-post/20_07/image-20201110154239594.png?lastModify=1612961813" alt="image-20201110154239594" style="zoom:33%;" />

<img src="file:///img/in-post/20_07/image-20201110154329811.png?lastModify=1612961813" alt="image-20201110154329811" style="zoom:33%;" />

<img src="file:///img/in-post/20_07/image-20201110154338263.png?lastModify=1612961813" alt="image-20201110154338263" style="zoom:33%;" />



> 其中,<img src="file:///img/in-post/20_07/image-20201110154859974.png?lastModify=1612961813" alt="image-20201110154859974" style="zoom:33%;" />
>
> 是编码器输出的特征.

<img src="file:///img/in-post/20_07/image-20201110155830392.png?lastModify=1612961813" alt="image-20201110155830392" style="zoom: 33%;" />

> 在获得重建损失后（图3中显示了一个示例），其中较大的损失表明该实例的深度学习模型未得到充分优化；损失分布的尾部应视为模型未知。 在这里，我们采用极值理论（EVT）通过对尾部的分布进行建模来找到未知类别. 
>
> EVT建议尾巴应为Weibull分布[65]。 对于一大类分布V和足够大的阈值w，{{V1，...，Vn}，n个独立且相同分布的样本，累积分布函数可以用广义的Pareto分布（GPD)
>
> `不懂???????`



<img src="file:///img/in-post/20_07/image-20201110160413820.png?lastModify=1612961813" alt="image-20201110160413820" style="zoom:33%;" />

## 实验描述

**错误分类的道路，房屋，直升机和卡车**
以下是普通/封闭分类。可以注意到训练样本中未包含某些分类。例如，对于上方的Salinas图像，农田之间的道路和房屋无法分类为任何已知类别，但是因为从不教它识别未知实例，所以深度学习模型仍然必须分配标签之一。

![](/img/in-post/20_07/mdl4ow1.png)

**我们的工作点：用黑色掩盖未知的事物**

通过使用多任务深度学习，使深度学习模型具有识别未知事物的能力：那些被黑色掩盖的事物。
对于Salinas，成功识别了农田之间的**道路和房屋**。
对于Pavia University，**直升机和卡车**被成功识别。

![](/img/in-post/20_07/mdl4ow2-20210106132634367.png)



# 实验

## 结果及复现

![image-20201110161315045](file:///img/in-post/20_07/image-20201110161315045.png?lastModify=1612961813)

> 在多次拍摄设置下，MDL4OW / C获得了最佳分类。 OA和F1比封闭分类高90.53％和0.9482，分别比封闭分类高1.87％和0.0083。 



![image-20201110162614041](file:///img/in-post/20_07/image-20201110162614041.png?lastModify=1612961813)

> 我们可以看到，所提出的方法成功地**识别了建筑物1，车辆（直升机和某些汽车），停车棚，和游泳池。**在这三种开放方法中，只有CROSR将building-2识别为未知，这在新颖类的F1高分中得到了体现。但是，CROSR在二级草地上的F1较低。此类在图像中覆盖了很大的区域，如示例实例的数量所示（表II）。如分类图所示（图4 CROSR），在图像的下部，一些草甸被CROSR误分类为未知。 **CROSR是一种基于质心的方法，对类内变异很敏感。 Meadows包含超过18000个实例，并且具有较大的类内差异，从而限制了基于质心的方法的性能。在遥感图像中，类内差异很大。因此，与CROSR相比，拟议的MDL4OW更加健壮和稳定。**

#### Salinas 20

![image-20210104102118382](file:///img/in-post/20_07/image-20210104102118382.png?lastModify=1612961813)

1. **model1 输出预测和重建的数据, model2 仅输出预测的类**

```python
if patch==9:
    model1,model2 = nw.resnet99_avg_recon(im1z,patch,cls1,l=1)
elif patch==5:
    model1,model2 = nw.wcrn_recon(im1z,cls1)
```

**patch==9， nw.resnet99_avg_recon **

64/64  loss: 0.0259 - output1_loss: 0.0448 - conv2d_transpose_4_loss: 0.0069 - output1_accuracy: 0.9828 - conv2d_transpose_4_accuracy: 0.6388

 

#### Salinas 200

![image-20210104102145512](/img/in-post/20_07/image-20210104102145512.png)





#### 重建可视化

> 我们用白色手动注释了一些人造材料. 我们可以看到，使用CROSR方法将许多已知实例（下部）误分类为未知。相反，提出的MDL4OW成功地**识别了未知物（左下方的道路和左上方的水池），同时又保持了已知类别的高精度。**

<img src="/img/in-post/20_07/image-20201110163614103.png" alt="image-20201110163614103" style="zoom: 33%;" />

> **由于提出的方法的一个关键假设是未知类将很难重建**，因此我们在图9中显示了Pavia数据集的原始和重建光谱图。树是Pavia数据集中的已知类之一。重建的光谱轮廓保留为经典植被曲线。重建的轮廓更紧密，表明组内差异较小。 Building-1是未知类之一。我们可以看到，重构后的光谱轮廓与原始光谱轮廓有很大不同。证实了未知类将很难重建的假设, 验证了实验的正确性(**This analysis confirms the assumption that** the unknown classes are poorly reconstructed, **indicating the effectiveness of the proposed method.**)

## 结果复现

**model1 输出预测和重建的数据, model2 仅输出预测的类**

```python
if patch==9:
    model1,model2 = nw.resnet99_avg_recon(im1z,patch,cls1,l=1)
elif patch==5:
    model1,model2 = nw.wcrn_recon(im1z,cls1)
```

**patch==9， nw.resnet99_avg_recon **

```
Model: "functional_1"  
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 9, 9, 204)]  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 7, 7, 32)     58784       input_1[0][0]                    
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 7, 7, 32)     58784       input_1[0][0]                    
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 7, 7, 64)     0           conv2d_1[0][0]                   
                                                                 conv2d[0][0]                     
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 7, 7, 64)     256         concatenate[0][0]                
__________________________________________________________________________________________________
activation (Activation)         (None, 7, 7, 64)     0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 7, 7, 64)     36928       activation[0][0]                 
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 7, 7, 64)     0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 7, 7, 64)     36928       activation_1[0][0]               
__________________________________________________________________________________________________
add (Add)                       (None, 7, 7, 64)     0           concatenate[0][0]                
                                                                 conv2d_3[0][0]                   
__________________________________________________________________________________________________
ploss (GlobalAveragePooling2D)  (None, 64)           0           add[0][0]                        
__________________________________________________________________________________________________
reshape (Reshape)               (None, 1, 1, 64)     0           ploss[0][0]                      
__________________________________________________________________________________________________
conv2d_transpose (Conv2DTranspo (None, 1, 1, 64)     4160        reshape[0][0]                    
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 1, 1, 64)     256         conv2d_transpose[0][0]           
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 1, 1, 64)     0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 3, 3, 64)     36928       activation_2[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 3, 3, 64)     0           conv2d_transpose_1[0][0]         
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 5, 5, 64)     36928       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 5, 5, 64)     256         conv2d_transpose_2[0][0]         
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 5, 5, 64)     0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_transpose_3 (Conv2DTrans (None, 7, 7, 64)     36928       activation_4[0][0]               
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 7, 7, 64)     0           conv2d_transpose_3[0][0]         
__________________________________________________________________________________________________
output1 (Dense)                 (None, 16)           1040        ploss[0][0]                      
__________________________________________________________________________________________________
conv2d_transpose_4 (Conv2DTrans (None, 9, 9, 204)    117708      activation_5[0][0]               
==================================================================================================
Total params: 425,884
Trainable params: 425,500
Non-trainable params: 384
__________________________________________________________________________________________________
```

# 改进想法

## 可以创新的地方

与对比学习结合, 度量学习结合, SimCLR

`尝试把分类图的0标签位置忽视`

原始：

|                                                              |                                                              |                                                              |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| <img src="/img/in-post/20_07/salinas_close_0.png" alt="salinas_close_0" style="zoom:50%;" /> | <img src="/img/in-post/20_07/salinas_mdl4ow_0.png" alt="salinas_mdl4ow_0" style="zoom:50%;" /> | <img src="/img/in-post/20_07/salinas_mdl4ow_classwise_0.png" alt="salinas_mdl4ow_classwise_0" style="zoom:50%;" /> |



##  改进实验

**数据：**

| 模型                                               | loss   | output1_loss | conv2d_transpose_4_loss | output1_accuracy | conv2d_transpose_4_accuracy | Train_time | Predict_time |
| :------------------------------------------------- | :----- | :----------- | :---------------------- | :--------------- | :-------------------------- | :--------- | :----------- |
| raw                                                | 0.0306 | 0.0527       | 0.0085                  | 0.9781           | 0.6633                      | 282        | 40           |
| 改进点1  全样本预训练（epoch=2）                   | 0.0243 | 0.0420       | 0.0065                  | **0.9828**       | **0.6984**                  | 436        | 39           |
| 改进点1  全样本预训练（epoch=6）                   | 0.0237 | 0.0410       | 0.0063                  | **0.9845**       | **0.7319**                  | 975        | 39           |
| 改进点1  全样本预训练 -0210 （一直冻结层）         | 0.0309 | 0.0309       | 0.0067                  | 0.9789           | **0.7253**                  | 2391       |              |
| **改进点1  全样本预训练 -0210 （冻-不冻结层）**    | 0.0206 | 0.0345       | 0.0066                  | **0.9867**       | 0.7249                      | 2395       |              |
| 改进点1  全样本预训练 -0210 （冻-不冻结层/2epoch） | 0.0257 | 0.0448       | 0.0066                  | 0.9789           | 0.7290                      | 3946       |              |



**5个样本**

| 模型                             | loss   | output1_loss | conv2d_transpose_4_loss | output1_accuracy | conv2d_transpose_4_accuracy | Train_time | Predict_time |
| :------------------------------- | :----- | :----------- | :---------------------- | :--------------- | :-------------------------- | :--------- | :----------- |
| raw                              | 0.0569 | 0.0923       | 0.0091                  | 0.9642           | 0.6309                      | \          | \            |
| 改进点1  全样本预训练（epoch=2） | 0.0033 | 0.0635       | 0.0068                  | **0.9751**       | **0.6620**                  | 321        | 40           |

**起始：**

| 模型                             | loss   | output1_loss | conv2d_transpose_4_loss | output1_accuracy | conv2d_transpose_4_accuracy |      |      |
| :------------------------------- | :----- | :----------- | :---------------------- | :--------------- | :-------------------------- | :--- | :--- |
| raw                              | 1.1228 | 2.1499       | 0.0957                  | 0.2164           | 0.0377                      |      |      |
| 改进点1  全样本预训练            | 0.9410 | 1.8694       | 0.0126                  | 0.3141           | 0.6655                      |      |      |
| 改进点1  全样本预训练（epoch=6） | 0.9176 | 1.8226       | **0.0125**              | **0.3398**       | **0.6766**                  |      |      |

**结果图：**

| 模型                              | salinas_close_0                                              | salinas_mdl4ow_0                                             | salinas_mdl4ow_classwise_0                                   |      |
| :-------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- | :--- |
| raw                               | ![salinas_close_0](file:///img/in-post/20_07/salinas_close_0.png?lastModify=1612962040) | <img src="file:///img/in-post/20_07/salinas_mdl4ow_0.png?lastModify=1612962040" alt="salinas_mdl4ow_0" style="zoom:67%;" /> | ![salinas_mdl4ow_classwise_0](file:///img/in-post/20_07/salinas_mdl4ow_classwise_0.png?lastModify=1612962040) |      |
| 改进点1  全样本预训练 （epoch=2） | ![image-20210106110727705](file:///img/in-post/20_07/image-20210106110727705.png?lastModify=1612962040) | <img src="file:///img/in-post/20_07/image-20210106111225188.png?lastModify=1612962040" alt="image-20210106111225188" style="zoom:67%;" /> | ![image-20210106110758647](file:///img/in-post/20_07/image-20210106110758647.png?lastModify=1612962040) |      |
| 改进点1  全样本预训练 （epoch=6） | ![image-20210106121822372](file:///img/in-post/20_07/image-20210106121822372.png?lastModify=1612962040) | <img src="file:///img/in-post/20_07/image-20210106121932292.png?lastModify=1612962040" alt="image-20210106112620219" style="zoom:67%;" /> | ![image-20210106125222424](file:///img/in-post/20_07/image-20210106125222424.png?lastModify=1612962040) |      |
| Reference                         |                                                              | <img src="file:///img/in-post/20_07/image-20210106112620219.png?lastModify=1612962040" alt="image-20210106112620219" style="zoom:67%;" /> |                                                              |      |



| 模型                                                  | 精度（conv2d_transpose_4_accuracy） | realmask图                                                   |      |
| :---------------------------------------------------- | :---------------------------------- | :----------------------------------------------------------- | :--- |
| 原始模型                                              | 0.6504                              | <img src="file:///img/in-post/20_07/image-20210106151722447.png?lastModify=1612962040" alt="image-20210106151722447" style="zoom:50%;" /> |      |
| 改进点 - 无标签全数据预训练  1epoch 的  realmask：    | 0.6672                              | ![image-20210106151139634](file:///img/in-post/20_07/image-20210106151139634.png?lastModify=1612962040) |      |
| 改进点 - **无标签**全数据预训练 6 epoch 的 realmask： | /                                   | ![image-20210106145547259](file:///img/in-post/20_07/image-20210106145547259.png?lastModify=1612962040) |      |
| 无标签预训练 + 有监督微调的realmask：                 | 0.7319                              | ![image-20210106141339131](file:///img/in-post/20_07/image-20210106141339131.png?lastModify=1612962040) |      |









