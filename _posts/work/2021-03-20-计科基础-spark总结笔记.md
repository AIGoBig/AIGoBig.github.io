# 参考

[spark MLLib guides](https://spark.apache.org/docs/latest/ml-guide.html)

# 概念

## Spark 是一个分布式计算平台。

### 何为分布式？

计算节点之间**不共享内存，需要通过网络通信的方式交换数据**。Spark 最典型的应用方式就是建立在大量廉价的计算节点上，这些节点可以是廉价主机，也可以是虚拟的 Docker Container（Docker 容器）。

### spark的架构是？

从下面 Spark 的架构图中我们可以看到，Spark 程序由 Manager Node（**管理节点**）进行调度组织，由 Worker Node（**工作节点**）进行具体的计算任务执行，最终将结果返回给 Drive Program（**驱动程序**）。在物理的 Worker Node 上，数据还会分为不同的 partition（**数据分片**），可以说 partition 是 Spark 的基础数据单元。

Spark 计算集群能够比传统的单机高性能服务器具备更强大的**计算能力，就是由这些成百上千，甚至达到万以上规模的工作节点并行工作带来的。**

<img src="/img/in-post/20_07/4ae1153e4daee39985c357ed796eca9b.jpeg" alt="img" style="zoom:50%;" />

> 图1 Spark架构图

### 那在执行一个具体任务的时候，Spark 是怎么协同这么多的工作节点，通过并行计算得出最终的结果呢？

这里我们用一个任务来解释一下 Spark 的工作过程。这个任务并不复杂，我们需要先从**本地硬盘**读取文件 textFile，再从**分布式文件系统 HDFS** 读取文件 hadoopFile，然后**分别**对它们进行处理，再把两个文件按照 ID 都 join 起来得到最终的结果。

这里你没必要执着于任务的细节，只要清楚任务的大致流程就好。在 Spark 平台上处理这个任务的时候，会将这个任务**拆解成一个子任务 DAG**（Directed Acyclic Graph，有向无环图），再根据 DAG 决定程序各步骤执行的方法。

从图 2 中我们可以看到，这个 Spark 程序分别从 textFile 和 hadoopFile 读取文件，再经过一系列 `map`、`filter` 等操作后进行 join，最终得到了处理结果。

<img src="/img/in-post/20_07/01524cdf0ff7f64bcf86c656dd5470fd.jpeg" alt="img" style="zoom:50%;" />

其中，最关键的过程是我们要理解哪些是可以纯并行处理的部分，哪些是必须 `shuffle`（混洗）和 `reduce` 的部分。

这里的 `shuffle` 指的是所有 partition 的数据**必须进行洗牌后才能得到下一步的数据**，最典型的操作就是图 2 中的 groupByKey 操作和 join 操作。以 join 操作为例，我们必须对 textFile 数据和 hadoopFile 数据做<u>全量的匹配</u>才可以得到 join 后的 dataframe（Spark 保存数据的结构）。而 groupByKey 操作则需要<u>对数据中所有相同的 key 进行合并</u>，也需要全局的 shuffle 才能完成。

与之相比，`map`、`filter` 等操作**仅需要逐条地进行数据处理和转换，不需要进行数据间的操作**，**因此各 partition 之间可以完全并行处理**。此外，在得到最终的计算结果之前，程序需要进行 reduce 的操作，从各 partition 上汇总统计结果，随着 partition 的数量逐渐减小，reduce 操作的并行程度逐渐降低，直到将最终的计算结果汇总到 master 节点（主节点）上。**可以说，shuffle 和 reduce 操作的触发决定了纯并行处理阶段的边界。**

<img src="/img/in-post/20_07/6e50b4010c27fac81acb0b230516e113.jpeg" alt="img" style="zoom:50%;" />

最后，我还想强调的是，shuffle 操作需要在不同计算节点之间进行数据交换，非常消耗计算、通信及存储资源，因此 <u>shuffle 操作是 spark 程序应该尽量避免的</u>。说了这么多，这里我们再用一句话总结 Spark 的计算过程：**Stage 内部数据高效并行计算，Stage 边界处进行消耗资源的 shuffle 操作或者最终的 reduce 操作。**





