---
layout: post
title: "如何自建远程服务器"
subtitle: ''
author: "Sun"
header-style: text
tags:
  - Linux
  - 
---

 

## 易学智能配置

![image-20200316100652945](/img/in-post/20_03/image-20200316100652945.png)

## 资料搜集

### Motivation

在2013年，MIT科技评论将深度学习列为当年十大科技突破之首。其原因在于，模型有其为庞大的网络结构，**参数够多，学习能力够强**，能配合大数据达到惊人的效果。而且，能自动学习特征，**避免了“特征工程”这种繁琐的手工劳动**。

三个选择项：
A、购买组装好的服务器，例如NVIDIA DIGITS DEVBOX
B、购买云服务，例如Amazon的GPU服务
C、自己攒一台深度学习服务器。

A项从性价比上不合算，而且不一定买的到。B项的云服务对于研究探索性质工作而言也比较贵，机器配置也不一定合适，所以我们就C项了。

### 硬件配置

[选择及参数参考](https://oldpan.me/archives/machine-deeplearning-station-list)

[如何自己打造一个深度学习服务器？](https://juejin.im/post/5b5448dfe51d45169c1c8ad2)

![image-20200318072701608](/img/in-post/20_03/image-20200318072701608.png)

| 需要买的 |                            |                 |      |
| -------- | -------------------------- | --------------- | ---- |
| **cpu**  | i5 8400                    | 1100            |      |
| **主板** | 微星 Z370M                 | 668             |      |
| **gpu**  | 1080 ?/2060/2080Ti(Tensor) | 2300/2900       |      |
| **内存** | 8G*2                       | 300()便宜的就行 |      |
| **电源** | 750W+                      |                 |      |
| 固态     | 240g                       | 320             |      |
|          |                            | 5000元          |      |
|          |                            |                 |      |

==TIM推荐==

[2019 年，如何配置一台以机器学习、深度学习为用途的工作站？](https://www.zhihu.com/question/310387269)

==强行分析一波深度学习配置推荐**==

[强行分析一波深度学习配置推荐](https://zhuanlan.zhihu.com/p/56075793)

##### ==Blog推荐==

硬件选择：基本思路是单显卡机器，保留升级空间

显卡选择：

显卡选择最重要，因为准备基于CUDA计算（CUDA (ComputeUnified Device Architecture) 是NVIDIA开发的GPU并行计算环境。）

有论文研究，**太高的精度对于深度学习的错误率是没有提升的，而且大部分的环境框架都只支持单精度，所以双精度浮点计算是不必要，Tesla系列都去掉了**。从显卡效能的指标看，**CUDA核心数要多，GPU频率要快，显存要大，带宽要高。**这样，最新==Titan X==算是价格便宜量又足的选择。**显存8G即可**

现在，**带宽、FLOPS 和 Tensor Core 的组合才是 GPU 性能的最佳指标**。

==只有RTX显卡具有RT核心和Tensor核心。==

> 考虑**矩阵乘法**的一个简单而有效的方法是：它是受带宽约束的。如果你想使用 LSTM 和其他需要做很多**矩阵乘法的循环网络**的话，**内存带宽**是 GPU 最重要的特性，
>
> 同样，**卷积受计算速度约束**。因此，对于 ResNets 和其他卷积体系结构来说，GPU 的 **TFLOP** 是其性能的最佳指标。
>
> **Tensor Cores** 稍微改变了这种平衡。Tensor Cores 是专用计算单元，可以加速计算——但不会加大内存带宽——因此对于**卷积网络来**说，最大的好处是 Tensor Core 可以使速度加快 30％到 100％。虽然 Tensor Cores 只能加快计算速度，但它们也**允许使用 16-bit 数字进行计算。**这也是矩阵乘法的一大优点，因为数字的大小只有 16-bit 而不是 32-bit，在内存带宽相同的矩阵中，数字的数量可以传输两倍。

 

> **运行环境**
>
> 首先，我们看一下Eric的硬件配置：
>
> **CPU**：AMD Ryzen 7 1700X 3.4GHz 8核 **主板**：MSI X370 Krait **内存**：32GB DDR4 **硬盘**：1TB NVMe 三星960Evo **显卡**：华硕GTX 1080Ti-11GB Turbo（**800美元**）、Palit RTX 2060–6GB（**350美元**）
>
> 软件环境：
>
> - Ubuntu 18.04 + Anaconda/Python 3.7
> - CUDA 10
> - **PyTorch 1.0** + **fastai 1.0**
> - Nvidia驱动版本：415.xx

|   目标GPU    | TFLOPS(单精度浮点性能) | CUDA核心(流处理器数目) | 带宽       | Tensor Cores | 跑分 | 内存 | 新价格     | 旧价格 |
| :----------: | ---------------------- | ---------------------- | ---------- | ------------ | ---- | ---- | ---------- | ------ |
|    1070ti    |                        |                        |            |              | 27W  | 8    |            | 2000   |
|     2060     | 6.5                    | 1920                   | 336        | yes          | 24W  | 6    |            |        |
| ~~**1080**~~ | 8.2                    | 2560                   |            |              | 30W  |      | 3000       | 2300   |
|              |                        |                        |            |              |      |      |            |        |
|  **2060s**   | 7.2                    | 2176                   | 448/256bit | yes          | 26W  | 8    | 2950七彩虹 |        |
|    1080ti    | 10.6                   | 3584                   |            |              | 38w  |      | 4200       | 3400   |
|              |                        |                        |            |              |      |      |            |        |

![英伟达20系Super显卡鲁大师跑分对比  老黄刀法精湛逼哭AMD！](https://img1.mydrivers.com/img/20190812/S160ac0a1-e7c5-4abe-9600-c56f5b7382cf.png)

![WechatIMG321](/img/in-post/20_03/WechatIMG321-4347995.jpeg)



![img](http://img.blog.itpub.net/blog/2019/04/11/8a2fb196df493cd4.jpeg?x-oss-process=style/bb)

![img](http://img.blog.itpub.net/blog/2019/04/11/e9f48eeaed266f83.jpeg?x-oss-process=style/bb)

CPU选择：
在深度学习任务中，CPU并不负责主要任务，单显卡计算时只有一个核心达到100%负荷，所以**CPU的核心数量和显卡数量一致即可**，太多没有必要，**但是处理PCIE的带宽要到40。**
cpu的PCIE通道不可太低，因为每一张显卡需要16个PCIE通道，如果cpu的PCIE通道小于16那么它和显卡的链接速度就会有影响，显卡的性能就不会完全发挥出来。如果多卡的话cpu的PCIE通道更要高。一般至强系列CPU的PCIe通道普遍比酷睿系列多一些。

主板选择：
需要支持**X99架构，支持PCIe3.0，还要支持4通道DDR4内存架构**。如果要搞四显卡并行，**PCIE带宽支持要达到40**，并且支持4-WayNVIDA SLI技术。

内存：
达到显存的二倍即可，当然有钱的话越大越好。

电源问题：一个显卡的功率接近300W，四显卡建议电源在1500W以上，为了以后扩展，选择了1600W的电源。

机箱散热：
因为各种部件相当庞大，需要有良好散热功能的大机箱，选择了Tt Thermaltake Core V51机箱，标配3个12cm风扇。未来如果需要还可以加装水冷设备。

软件环境安装：

主要安装了Ubuntu系统，CUDA环境，以及theano、keras环境

最后的硬件配置：
CPU: Intel X99平台 i7 5960K
内存: DDR4 2800 32G(8G*4)
主板: GIGABYTE X99-UD4
显卡: GTX Titan X
**硬盘: SSD+普通硬盘**

系统和软件
**操作系统: Ubuntu 14.04.3 x64**
CUDA: 7.5
Anaconda 2.3
Theano 7.0

##### ==针对不同研究目的、不同预算，Tim给出了如下的建议：==

通过**16位训练**，你可以拥有几乎16位的显存，相当于将显存翻了一倍。也就是说，16位计算可以节省50%的内存，16位 8GB显存大小与12GB 32位显存大小相当。

最佳GPU**：RTX 2070

**避免的坑**：所有Tesla、Quadro、创始人版（Founders Edition）的显卡，还有Titan RTX、Titan V、Titan XP

**高性价比**：==RTX 2070（高端），RTX 2060或GTX 1060 (6GB)==（中低端）

**穷人之选**：GTX 1060 (6GB)

**破产之选**：GTX 1050 Ti（4GB），或者CPU（原型）+ AWS / TPU（训练），或者Colab

**Kaggle竞赛**：RTX 2070

**计算机视觉或机器翻译研究人员**：采用鼓风设计的GTX 2080 Ti，如果训练非常大的网络，请选择RTX Titans

**NLP研究人员**：RTX 2080 Ti

**已经开始研究深度学习**：RTX 2070起步，以后按需添置更多RTX 2070

**尝试入门深度学习**：GTX 1050 Ti（2GB或4GB显存）



### [如何从零开始搭建深度学习工作站(含CUDA安装等)](https://zhuanlan.zhihu.com/p/38380103)

**一、显卡 GPU**

如果要扩展4卡，对主板和CPU的选购会有特殊的要求，整体的价格也会贵至少2倍以上。对于一般使用场景，建议单卡入门，最多支持扩展到2卡就行了。

![img](https://pic1.zhimg.com/80/v2-88d09d2e1d7f3d48380db37e2a0f5adc_720w.jpg)

上一代或最新一代的I7 超频版 CPU是个不错的选择，核心多，频率高。

**三、主板**

主板作为整个系统的地基，需要有个全局性的考虑，虽然不像CPU和显卡一般有明显的性能差异，但决定了整个主机的硬件层次及后期的升级。建议直接购买**一线品牌**，质量、做工及稳定性方面都有保障。再加上只考虑支持双显卡交火，目前市面上大多数的系列都兼容。

**四、存储**

内存方面首选金士顿，占了市场60%以上的份额，口碑和质量都有保持。建议组**多通道及选DDR4 2400以上的频率**。

由于深度学习只需要在运行处理大量数据，**平时存储时对速度要求并不高**。可以采取**普通的机械硬盘（HDD）和固态硬盘（SSD）相结合**的方式，兼顾速度和存储要求。机械硬盘从西数和希捷中挑一个就行，建议2T以上容量，容量越大，性价比越高，相比其它硬件，完全是白菜价了。固态硬盘速度比机械硬盘快了几倍，对系统整体性能有很大提升，缺点就是一个字：贵。所以**容量方面建议至少要256G**，有经济实力的就直接512G吧，一步到位。固态硬盘还有个要考虑的因素是接口规格了，目前主流的有SATA3和M.2两种。**M.2速度快**，但有些主板识别不到，==**导致在安装操作系统(Ubuntu)时无法安装在固态硬盘上**==。



### TODO:

关于如何用自己的电脑建立远程服务器? 首先有以下几个问题需要弄明白:

#### **关于服务器**

1. 可以自己做远程服务器吗?

要想搭建成为服务器，首先要能够**通过路由器将个人电脑暴露于外网**，使得网络上的其他主机能够访问到你的个人电脑。其次，**个人电脑的IP地址必须转变为静态**，否则你的电脑IP地址会不固定，网络上的其他主机也难以访问到你的个人电脑。

​	linux系统么
​	如何用命令行远程操作
​	如何远程看训练曲线
​		visdom/tensorboardX远程
​	如何复制文件 

​	关于是否自动开机

​		自启动设置

#### **GPU**

​	深度学习GPU最全对比，到底谁才是性价比之王？ | 选购指南
​	电源功率够吗
​	如何配置cuda

