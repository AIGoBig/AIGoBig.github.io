# Introduction

## Why pytorch？

### 更加“Python化”，更易于使用

每一个Pytorch示例（CV和NLP）都有共同的结构：

```python
data/
experiments/
model/
	net.py：指定神经网络架构、损失函数和评估指标。
	data_loader.py：指定数据应如何馈送到网络。
train.py：包含主训练循环。
evaluate.py：包含用于评估模型的主循环。
search_hyperparams.py
synthesize_results.py
evaluate.py
utils.py：用于处理超参数 / 日志 / 存储模型的实用功能。
```

### 有用的库

下面是一个综合列表，列出了计算机视觉、自然语言处理和生成库等不同领域的一些项目：

- pro_gan_pytorch：利用 ProGAN 功能。
- BoTorch：使用[贝叶斯](https://www.infoq.cn/article/2014/07/programming-language-bayes)优化。
- ParlAI：用于共享、训练和测试对话模型。
- OpenNMT-py：用于实现神经机器翻译系统。
- MUSE：用于多语言词嵌入。
- **skorch：用于将 scikit-learn 代码与 PyTorch 融合。**

### 易于实现数据并行

Distributed Data-Parallel（分布式数据并行）是 PyTorch 的一项特性，你可以将其与 Data-Parallel（数据并行）结合使用来处理需要大型数据集和模型的用例。

为实现数据并行，使用了`torch.nn.DataParallel`类

### 增加了对移动设备的支持

如Android和IOS设备部署的支持

**PyTorch Mobile 入门：**

- Android：[ https://pytorch.org/mobile/android](https://pytorch.org/mobile/android)
- iOS：[ https://pytorch.org/mobile/ios](https://pytorch.org/mobile/ios)

### 易于调试

pytorch的动态计算图允许在代码执行时进行动态修改和快速调试

# 使用方式

## torch 与 numpy

互相转换

```python
np_data = np.arange(6).reshape((2, 3))
torch_data = torch.from_numpy(np_data)
tensor2array = torch_data.numpy()
```

运算形式

1. 注意torch中的数据形式是`Tensor`

```python
# abs 绝对值计算
data = [-1, -2, 1, 2]
tensor = torch.FloatTensor(data)  # 转换成32位浮点 tensor
print(
    '\nabs',
    '\nnumpy: ', np.abs(data),          # [1 2 1 2]
    '\ntorch: ', torch.abs(tensor)      # [1 2 1 2]
)
```

2. Autograd automatically supports Tensors with requires_grad set to True.  计算图可以通过链式法则求导。如果`variables`中的任何一个`variable`是 非标量(`non-scalar`)的，且`requires_grad=True`。

# 逻辑回归程序（关系拟合）

1. Class里，`__init__()`是定义各层，`forward()`才是真正搭建网络

2. `unsqueeze(1)`的使用是因为将数据从1维变2维，因为pytorch只能处理带patch的二维数据

3. `hidden`是`Linear()`的一个实例，后面是它这一层的内容, 故可以对其传入参数

4. 训练前对优化器和损失函数进行选择

   ```python
   optimizer = t.optim.SGD(net.parameters(), lr=0.2)  # 传入net的参数 和 lr
   loss_func = t.nn.MSELoss()      # 回归问题用均方差误差即可
   ```

5. 优化过程

   ```Python
       optimizer.zero_grad()   # 清空上一次计算的梯度，初始化为0.  相当于d_weights = [0] * n
       loss.backward()         # 误差反向传播，计算梯度作为参数更新值.  相当于 w.grad = ▽loss/▽w
       optimizer.step()        # 通过step()进行单次优化.  相当于 w = w - lr*w.grad b = b - lr*b.grad
   ```

   1. 为什么要用`optimizer.zero_grad()`把梯度清零?

      1. 进来一个batch的数据, 就会计算一次梯度, 更新一次网络.
      2. 可以实现梯度累加等Trick:
         https://www.zhihu.com/question/303070254

   2. **每个batch的操作与基础代码对应关系**
      pytorch中:

      ```python
              # zero the parameter gradients
              optimizer.zero_grad()
              # forward + backward + optimize
              outputs = net(inputs)
              loss = criterion(outputs, labels)
              loss.backward()
              optimizer.step()
      ```

      基础实现:

      ```python
          # gradient descent
          weights = [0] * n
          alpha = 0.0001
          max_Iter = 50000
          for i in range(max_Iter):
              loss = 0
              # optimizer.zero_grad()
              d_weights = [0] * n
              for k in range(m):
                 #  outputs = net(inputs)
                  h = dot(input[k], weights)
                  # loss.backward()
                  d_weights = [d_weights[j] + (label[k] - h) * input[k][j] for j in range(n)] 
                  # loss = criterion(outputs, labels)
                  loss += (label[k] - h) * (label[k] - h) / 2
              d_weights = [d_weights[k]/m for k in range(n)]
              # optimizer.step()
              weights = [weights[k] + alpha * d_weights[k] for k in range(n)]
              if i%10000 == 0:
                  print "Iteration %d loss: %f"%(i, loss/m)
                  print weight
      ```

      1. **optimizer.zero_grad()对应d_weights = [0] \* n**
         梯度初始化为零, 一个batch的loss关于weight的导数是所有sample的loss关于weight的导数的累加和

      2. **outputs = net(inputs)对应h = dot(input[k], weights)**

         即前向传播求出预测的值

      3. **loss = criterion(outputs, labels)对应loss += (label[k] - h) \* (label[k] - h) / 2**

         这一步很明显，就是求loss（其实我觉得这一步不用也可以，反向传播时用不到loss值，只是为了让我们知道当前的loss是多少）

      4. **loss.backward()对应d_weights = [d_weights[j] + (label[k] - h) \* input\[k][j] for j in range(n)]**

         即反向传播求梯度

      5. **optimizer.step()对应weights = [weights[k] + alpha \* d_weights[k] for k in range(n)]**

         即更新所有参数

6. 使用`imageio`进行GIF绘制。

![LR_fitting](/img/in-post/20_07/LR_fitting.gif)

```python
import numpy as np

import torch.nn as nn
import os
from tqdm import tqdm
os.environ['KMP_DUPLICATE_LIB_OK']='True'		# macOS系统原因需要加上这一句可正常运行

"""
建立数据集   
"""
import torch as t
import matplotlib.pyplot as plt
import imageio
from matplotlib.animation import FuncAnimation
plt.style.use('seaborn')  # 设置使用的样式
import seaborn
# y = a * x^2 + b
# shape=(100, 1),1维变2维，因为pytorch只能处理带patch的二维数据
x = t.linspace(-1,1,100).unsqueeze(1)
y  = x.pow(2) + 0.1 * t.randn(x.size())
x.sort()
plt.scatter(x, y)
plt.show()

"""
建立神经网络
"""
import torch.nn.functional as F  # 激励函数
class Net(t.nn.Module):
    """
    __init__()是定义各层
    forward()才是真正搭建网络
    """
    def __init__(self, n_feature, n_hidden, n_output):
        super(Net, self).__init__()
        # 其实每个层就是一个带参数的广义函数映射
        self.hidden = nn.Linear(n_feature, n_hidden)  # hidden是属性，后面是它这一层的内容
        self.output = nn.Linear(n_hidden, n_output)

    def forward(self, x):  # module中的forward功能
        # 正向传播初入值， 用神经网络分析出输出值
        # hidden获得的值是torch.nn.Linear的一个实例，然后Linear又是Module的子类，
        # 所以hidden相当于is a Module，Module中实现了__call__()方法，Module类型的所有实例都是可以被当成一个方法来调用的。
        x = F.relu(self.hidden(x))
        x = self.output(x)
        return x


net = Net(1, 10, 1)  # 输入x，隐藏单元10个，输出y
print(net)  # 可以打印网络结构

"""
训练网络
"""
optimizer = t.optim.SGD(net.parameters(), lr=0.2)  # 传入net的参数 和 lr
loss_func = t.nn.MSELoss()      # 回归问题用均方差误差即可

# plt.ion()   # 设置为实时打印的画图

image_list = []
for _ in tqdm(range(200)):
    prediction = net(x)

    loss = loss_func(prediction, y)  # 计算误差

    """优化"""
    optimizer.zero_grad()   # 清空上一步残余更新参数值，要把梯度清零
    loss.backward()         # 误差反向传播，计算梯度作为参数更新值
    optimizer.step()        # step()进行单次优化，将参数重新施加到net的parameters上

    """可视化"""
    if _ % 10 == 0:
        # plot and show learning process
        plt.cla()
        plt.scatter(x.data.numpy(), y.data.numpy())
        line =plt.plot(x.data.numpy(), prediction.data.numpy(), 'r-',  lw=5)
        plt.text(0.5, 0, 'Loss=%.4f' % loss.data.numpy(), fontdict={'size': 20, 'color':  'red'})

        # 生成动态图
        plt.savefig("temp.jpg")
        plt.pause(0.1)
        image_list.append(imageio.imread("temp.jpg"))  # 可以不用循环i，直接用列表形式
        # print(image_list)
        # duration 是图像间的间隔
imageio.mimsave('LR_fitting.gif', image_list,'GIF', duration=0.2)

# plt.ioff()
# plt.show()
```

# 分类程序（区分类型）

1. 注意其与回归网络的不同之处：

   1.  网络输入输出节点数不同

      ```python
      net = Net(2, 10, 2)  # 输入输出类别需要因任务而异
      ```

   2. 分类问题使用交叉熵损失函数, 回归问题使用MSE

      ```python
      loss_func = t.nn.CrossEntropyLoss()      # 注意多分类用CrossEntropyLoss  [0, 0, 1] -> [0.2, 0.1, 0.7]
      ```

   3. 经过一个F.softmax()才是概率值, 取最大作为预测输出

      ```python
      prediction = t.max(F.softmax(out), 1)[1]    # max()[1]取索引(label)
      ```

   

2. `torch.normal(_mean_, _std_, _*_, _generator=None_, _out=None_)` → `Tensor`    

   返回从单独的**正态分布**中得出均值和标准差的随机数张量.

   [`mean`](https://s0pytorch0org.icopy.site/docs/master/generated/torch.mean.html#torch.mean)是具有每个输出元素的正态分布平均值的张量

   [`std`](https://s0pytorch0org.icopy.site/docs/master/generated/torch.std.html#torch.std)是一个张量，每个输出元素的正态分布的标准偏差

   [`mean`](https://s0pytorch0org.icopy.site/docs/master/generated/torch.mean.html#torch.mean)和[`std`](https://s0pytorch0org.icopy.site/docs/master/generated/torch.std.html#torch.std)的形状不需要匹配，但是每个张量中元素的总数必须相同.

   Example:

   ```python
   >>> torch.normal(mean=torch.arange(1., 11.), 
                    std=torch.arange(1, 0, -0.1))
   
   tensor([ 1.0425, 3.5672, 2.7969, 4.2925, 4.7229, 6.2134,  8.0505, 8.1408, 9.0563, 10.0566])
   ```

3. `torch.cat()`合并数据

   ```python
   # 注意 x, y 数据的数据形式是一定要像下面一样 (torch.cat 是在合并数据)
   # 合并x当做数据， y当做标签，注意标签的类型应该是LongTensor
   x = t.cat((x0, x1), 0).type(t.FloatTensor)  # FloatTensor = 32-bit floating
   y = t.cat((y0, y1), ).type(t.LongTensor)    # LongTensor = 64-bit integer
   ```

4. 根据`c`的标签不同颜色染色

   ```python
   plt.scatter(x.data.numpy()[:, 0], x.data.numpy()[:, 1], c=y.data.numpy(), s=100, lw=0, cmap='RdYlGn')
   ```

![Classification](/img/in-post/20_07/Classification-6439734.gif)

```python
import torch.nn as nn
import os
from tqdm import tqdm
os.environ['KMP_DUPLICATE_LIB_OK']='True'
import torch as t
import matplotlib.pyplot as plt
import imageio
plt.style.use('seaborn')  # 设置使用的样式


"""
建立数据集   
"""
# 假数据, 中心点分别为(2,2)和(-2,-2)的两个正态分布的数据
n_data = t.ones(100, 2)         # 数据的基本形态
x0 = t.normal(2*n_data, 1)      # 类型0(label) x data (tensor), shape=(100, 2)
y0 = t.zeros(100)               # 类型0(label) y data (tensor), shape=(100, )
x1 = t.normal(-2*n_data, 1)     # 类型1 x data (tensor), shape=(100, 1)
y1 = t.ones(100)                # 类型1 y data (tensor), shape=(100, )

# 注意 x, y 数据的数据形式是一定要像下面一样 (torch.cat 是在合并数据)
# 合并x当做数据， y当做标签，注意标签的类型应该是LongTensor
x = t.cat((x0, x1), 0).type(t.FloatTensor)  # FloatTensor = 32-bit floating
y = t.cat((y0, y1), ).type(t.LongTensor)    # LongTensor = 64-bit integer

# 根据c的标签不同颜色染色
plt.scatter(x.data.numpy()[:, 0], x.data.numpy()[:, 1], c=y.data.numpy(), s=100, lw=0, cmap='RdYlGn')
plt.show()


"""
建立神经网络
"""
import torch.nn.functional as F  # 激励函数
class Net(t.nn.Module):
    """
    __init__()是定义各层
    forward()才是真正搭建网络
    """
    def __init__(self, n_feature, n_hidden, n_output):
        super(Net, self).__init__()
        self.hidden = nn.Linear(n_feature, n_hidden)  # hidden是属性，后面是它这一层的内容
        self.output = nn.Linear(n_hidden, n_output)

    def forward(self, x):  
        # module中的forward功能，正向传播初入值， 用神经网络分析出输出值
        x = F.relu(self.hidden(x))
        x = self.output(x)
        return x


net = Net(2, 10, 2)  # 输入输出类别需要因任务而异
print(net)  


"""
训练网络
"""
optimizer = t.optim.SGD(net.parameters(), lr=0.01)  # 传入net的参数 和 lr, 为了演示将lr调小
loss_func = t.nn.CrossEntropyLoss()      # 注意多分类用CrossEntropyLoss  [0, 0, 1] -> [0.2, 0.1, 0.7]

# plt.ion()   # 设置为实时打印的画图

image_list = []
for _ in tqdm(range(100)):
    out = net(x)    # 分类是out, [-2, -0.12, 20]， 需要再加入激活层转化为概率 ：F.softmax(out)

    loss = loss_func(out, y)  # 计算误差

    """优化"""
    optimizer.zero_grad()   # 清空上一步残余更新参数值，要把梯度清零
    loss.backward()         # 误差反向传播，计算梯度作为参数更新值
    optimizer.step()        # step()进行单次优化，将参数重新施加到net的parameters上

    """可视化"""
    if _ % 2 == 0:
        plt.cla()
        # 过了一道 softmax 的激励函数后的最大概率才是预测值
        prediction = t.max(F.softmax(out), 1)[1]    # max()[1]取索引(label)
        pred_y = prediction.data.numpy().squeeze()
        target_y = y.data.numpy()
        plt.scatter(x.data.numpy()[:, 0], x.data.numpy()[:, 1], c=pred_y, s=100, lw=0, cmap='RdYlGn')
        accuracy = sum(pred_y == target_y) / 200.  # 预测中有多少和真实值一样
        plt.text(1.5, -4, 'Accuracy=%.2f' % accuracy, fontdict={'size': 20, 'color': 'red'})

        # 生成动态图
        plt.savefig("temp.jpg")
        plt.pause(0.1)
        image_list.append(imageio.imread("temp.jpg"))  # 可以不用循环i，直接用列表形式

imageio.mimsave('Classification.gif', image_list,'GIF', duration=0.05)   # duration 是图像间的间隔

# plt.ioff()
# plt.show()
```

# 更快的搭建神经网络

由输出可以发现, net2将激活函数也纳入网络中了, 但net中激活函数是在forward()中才被调用, 说明:

 `net` 的好处就是你可以根据你的个人需要更加个性化你自己的**前向传播过程**, 比如(RNN). 

`net2`的好处是更加简单

> F.relu() 是一个function
>
> nn.ReLU() 是一个class

```python
net2 = nn.Sequential(
    nn.Linear(1, 10),
    nn.ReLU(),
    nn.Linear(10,1)
)
print(net)
print(net2)
```

输出:

```
Net( 		# 正常搭建
  (hidden): Linear(in_features=1, out_features=10, bias=True)
  (output): Linear(in_features=10, out_features=1, bias=True)
)
Sequential(
  (0): Linear(in_features=1, out_features=10, bias=True)
  (1): ReLU()
  (2): Linear(in_features=10, out_features=1, bias=True)
)
```

# 保存和恢复模型

1. 保存网络

   ```python
       t.save(net1, './Try_ModelSaved/net.pkl')  # 保存整个网络
       t.save(net1.state_dict(), './Try_ModelSaved/net_params.pkl')  # 只保存参数,速度快
   ```

2. 恢复整个网络

   ```python
       net2 = t.load('./Try_ModelSaved/net.pkl')  # restore entire net1 to net2
       prediction = net2(x)
   ```

3. 恢复网络参数

   ```python
       """新建 net3"""
       net3 = t.nn.Sequential(
           nn.Linear(1, 10),
           nn.ReLU(),
           nn.Linear(10, 1)
       )
       """将参数复制到net3中"""
       net3.load_state_dict(t.load('./Try_ModelSaved/net_params.pkl'))
       prediction = net3(x)	
   ```

由图可以看出3个net得到的回归曲线完全相同, 因为它们的内部参数都是完全相同的.

![ModelSaveUse_10hidden](/img/in-post/20_07/ModelSaveUse_10hidden.png)

> hidden layer nodes == 10

![ModelSaveUse_100hidden](/img/in-post/20_07/ModelSaveUse_100hidden.png)

> hidden layer nodes == 100, 增加宽度后拟合效果明显好与hidden layer nodes == 10的网络.

完整代码:

```python
import os
os.environ['KMP_DUPLICATE_LIB_OK']='True'
import imageio
from tqdm import tqdm
import torch as t
import torch.nn as nn
import matplotlib.pyplot as plt
plt.style.use('seaborn')  # 设置使用的样式

t.manual_seed(1)    # reproducible

# 假数据
x = t.unsqueeze(t.linspace(-1, 1, 100), dim=1)  # x data (tensor), shape=(100, 1)
y = x.pow(2) + 0.2*t.rand(x.size())  # noisy y data (tensor), shape=(100, 1)


def savemodel():
    """
    保存网络
    """
    # Build Net
    net1 = nn.Sequential(
        nn.Linear(1, 10),
        nn.ReLU(),
        nn.Linear(10, 1)
    )
    optimizer = t.optim.SGD(net1.parameters(), lr=0.5)
    loss_func = t.nn.MSELoss()

    # Train
    for _ in range(100):
        prediction = net1(x)
        loss = loss_func(prediction, y)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    """Save model"""
    t.save(net1, './Try_ModelSaved/net.pkl')  # 保存整个网络
    t.save(net1.state_dict(), './Try_ModelSaved/net_params.pkl')  # 只保存参数,速度快


def restore_net():
    """
    提取整个网络
        网络大时可能会慢
    """
    net2 = t.load('./Try_ModelSaved/net.pkl')  # restore entire net1 to net2
    prediction = net2(x)

def restore_params():
    """
    提取网络参数
        提取参数, 放入新建的网络中
    """
    """新建 net3"""
    net3 = t.nn.Sequential(
        nn.Linear(1, 10),
        nn.ReLU(),
        nn.Linear(10, 1)
    )
    """将参数复制到net3中"""
    net3.load_state_dict(t.load('./Try_ModelSaved/net_params.pkl'))
    prediction = net3(x)


savemodel()
restore_net()
restore_params()
```

# 批训练 — DataLoader

1. 批训练可以有很多种途径, 详情请见 [我制作的 训练优化器 动画简介](https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-06-speed-up-learning/).
2. Torch 中提供了一种帮你**整理你的数据结构**的好东西, `DataLoader` 是 torch 给你用来包装你的数据的工具. 
   1. 作用: **包装自己的数据, 进行批训练**. 
   2. 过程
      1. **将自己的 (numpy array 或其他) 数据形式装换成 Tensor **
      2. **然后再放进这个包装器中**. 
   3. 好处: **他们帮你有效地迭代数据** 

3. `DataLoader`核心代码

   ```python
   import torch,utils.data as Data
   # 把 dataset 放入 DataLoader
   loader = Data.DataLoader(
       dataset=torch_dataset,      # torch TensorDataset format
       batch_size=BATCH_SIZE,      # mini batch size
       shuffle=True,               # 要不要打乱数据 (打乱比较好)
       num_workers=2,              # 多线程来读数据
   )				
   ```

4. 细节:
   
   1. 如果最后的`step`里数据不够一个`batch_size`时, 最后一个`step`会输出剩下的数据

完整示例代码:

```python
import os
os.environ['KMP_DUPLICATE_LIB_OK']='True'
import imageio
from tqdm import tqdm
import torch as t
import torch.nn as nn
import torch.utils.data as Data
import matplotlib.pyplot as plt
plt.style.use('seaborn')  # 设置使用的样式

t.manual_seed(1)    # reproducible

BATCH_SIZE = 5      # 批训练的数据个数

x = t.linspace(1, 10, 10)       # x data (torch tensor)
y = t.linspace(10, 1, 10)       # y data (torch tensor)

# 先转换成 torch 能识别的 Dataset
torch_dataset = Data.TensorDataset(x, y)

# 把 dataset 放入 DataLoader
loader = Data.DataLoader(
    dataset=torch_dataset,      # torch TensorDataset format
    batch_size=BATCH_SIZE,      # mini batch size
    shuffle=True,               # 要不要打乱数据 (打乱比较好)
    num_workers=2,              # 多线程来读数据
)

for epoch in range(3):
    for step, (batch_x, batch_y) in enumerate(loader):
        # 假设这里就是你训练的地方...

        # 打出来一些数据
        print('Epoch:', epoch, '| Step:', step, '| batch x:',
              batch_x.numpy(), '| batch y:', batch_y.numpy())
```

输出:

```
Epoch: 0 | Step: 0 | batch x: [ 5.  7. 10.  3.  4.] | batch y: [6. 4. 1. 8. 7.]
Epoch: 0 | Step: 1 | batch x: [2. 1. 8. 9. 6.] | batch y: [ 9. 10.  3.  2.  5.]
Epoch: 1 | Step: 0 | batch x: [ 4.  6.  7. 10.  8.] | batch y: [7. 5. 4. 1. 3.]
Epoch: 1 | Step: 1 | batch x: [5. 3. 2. 1. 9.] | batch y: [ 6.  8.  9. 10.  2.]
Epoch: 2 | Step: 0 | batch x: [ 4.  2.  5.  6. 10.] | batch y: [7. 9. 6. 5. 1.]
Epoch: 2 | Step: 1 | batch x: [3. 9. 1. 8. 7.] | batch y: [ 8.  2. 10.  3.  4.]
```

# 不同的优化器 — 加速神经网络训练

1. 主要有以下几种模式

   1. Stochastic Gradient Descent(SGD)
   2. Momentum
   3. AdaGrad
   4. RMSProp
   5. **Adam**

2. 图示:

   <img src="/img/in-post/20_07/speedup3.png" alt="speedup3" style="zoom:67%;" />

   原始形式:

   <img src="/img/in-post/20_07/speedup4.png" alt="加速神经网络训练 (Speed Up Training)" style="zoom: 50%;" />

   Momentum:

   <img src="/img/in-post/20_07/speedup5.png" alt="加速神经网络训练 (Speed Up Training)" style="zoom:50%;" />

   Adam:

   <img src="/img/in-post/20_07/speedup8.png" alt="加速神经网络训练 (Speed Up Training)" style="zoom:50%;" />

   >  `SGD` 是最普通的优化器, 也可以说没有加速效果, 而 `Momentum` 是 `SGD` 的改良版, 它加入了动量原则. 后面的 `RMSprop` 又是 `Momentum` 的升级版. 而 `Adam` 又是 `RMSprop` 的升级版. 不过从这个结果中我们看到, `Adam` 的效果似乎比 `RMSprop` 要差一点. 所以说并不是越先进的优化器, 结果越佳. 我们在自己的试验中可以尝试不同的优化器, 找到那个最适合你数据/网络的优化器.

1. 注意画不同的图的时候要建立不同的`plt.figure()`

2. 待分类数据:

   ![Optimizer_data](/img/in-post/20_07/Optimizer_data.png)
   不同优化器对比结果:
   ![Optimizer](/img/in-post/20_07/Optimizer-6504925.png)

完整代码:

```python
import os
os.environ['KMP_DUPLICATE_LIB_OK']='True'
import imageio
from tqdm import tqdm
import torch as t
import torch.nn as nn
import torch.utils.data as Data
import matplotlib.pyplot as plt
import torch.nn.functional as F
plt.style.use('seaborn')  # 设置使用的样式

t.manual_seed(1)    # reproducible

LR = 0.01
BATCH_SIZE = 32      # 批训练的数据个数
EPOCH = 12

# fake dataset
x = t.unsqueeze(t.linspace(-1, 1, 1000), dim=1)
y = x.pow(2) + 0.1*t.normal(t.zeros(*x.size()))

# 注意画不同的图的时候要建立不同的`plt.figure()`
plt.figure()
plt.scatter(x.numpy(), y.numpy())
plt.show()

# 使用上节内容提到的 data loader
torch_dataset = Data.TensorDataset(x, y)
loader = Data.DataLoader(dataset=torch_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2,)


# 为了对比每一种优化器, 我们给他们各自创建一个神经网络, 但这个神经网络都来自同一个 Net 形式.
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.hidden = nn.Linear(1, 10)
        self.predict = nn.Linear(10, 1)

    def forward(self, x):
        x = self.hidden(x)
        x = F.relu(x)
        x = self.predict(x)
        return x

net_SGD         = Net()
net_Momentum    = Net()
net_RMSprop     = Net()
net_Adam        = Net()
nets = [net_SGD, net_Momentum, net_RMSprop, net_Adam]

opt_SGD         = t.optim.SGD(net_SGD.parameters(), lr=LR)
opt_Momentum    = t.optim.SGD(net_Momentum.parameters(), lr=LR, momentum=0.8)
opt_RMSprop     = t.optim.RMSprop(net_RMSprop.parameters(), lr=LR, alpha=0.9)
opt_Adam        = t.optim.Adam(net_Adam.parameters(), lr=LR, betas=(0.9, 0.99))
optimizers = [opt_SGD, opt_Momentum, opt_RMSprop, opt_Adam]

loss_func = nn.MSELoss()
losses_his = [[], [], [], []]   # record the loss of 4 net

for epoch in range(EPOCH):
    print('Epoch:', epoch)
    for step, (b_x, b_y) in enumerate(loader):

        # 通过数组的形式, 迭代4次
        for net, opt, l_his in zip(nets, optimizers, losses_his):
            output = net(b_x)
            loss = loss_func(output, b_y)

            opt.zero_grad()
            loss.backward()
            opt.step()      # 为每个节点重设梯度
            l_his.append(loss.data.numpy())

# 注意画不同的图的时候要建立不同的`plt.figure()`
plt.figure()       
labels = ['SGD', 'Momentum', 'RMSprop', 'Adam']
for i, l_his in enumerate(losses_his):
    plt.plot(l_his, label=labels[i])
plt.legend(loc='best')
plt.xlabel('Steps')
plt.ylabel('Loss')
plt.ylim((0, 0.2))
plt.show()
```

# CNN — MNIDT分类

1. 加载数据
   1. 选一个样本进行输出
      <img src="/img/in-post/20_07/image-20200804154520873.png" alt="image-20200804154520873" style="zoom: 25%;" />

2. 下载数据集方法

   ```python
   train_data = torchvision.datasets.MNIST(
       root='Volumes/ArcFile/mnist/',
       train=True,  # this is training data
       # PIL.Image or numpy.ndarray to torch.FloatTensor(C * H * W), and normalize in the range [0.0, 1.0]
       transform=torchvision.transforms.ToTensor(),
   
       download=DOWNLOAD_MNIST
   )
   ```

3. t-SNE聚类及可视化

   `low_dim_embs = tsne.fit_transform(last_layer.data.numpy()[:plot_only, :]) `, ==**通过最后一层的pixel进行t-SNE分类可视化**==

   ```python
   test_output, last_layer = cnn(test_x)  # x 赋值给 last_layer
   
   # Visualization of trained flatten layer (T-SNE)
   tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)
   plot_only = 500
   low_dim_embs = tsne.fit_transform(last_layer.data.numpy()[:plot_only, :])  # 通过最后一层的pixel进行t-SNE分类可视化
   ```

3. CNN模型

   1. 通过padding, 经过卷积层图片大小不变
   2. 注意全连接层输入是batch_size个一维向量 — (32\*7*7, 10)
   3. 可视化时需要 return x 来返回

   ```python
   class CNN(t.nn.Module):
       def __init__(self):
           super(CNN, self).__init__()
           self.conv1 = nn.Sequential(
               # input shape (1, 28, 28) -> (16, 28, 28) -> (16, 14, 14)
               nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2),  # conv后的图片大小不变
               nn.ReLU(),
               nn.MaxPool2d(kernel_size=2))
           self.conv2 = nn.Sequential(
               # input shape (16, 14, 14) -> (32, 14, 14) -> (32, 7, 7)
               nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2),
               nn.ReLU(),
               nn.MaxPool2d(kernel_size=2))
           self.out = nn.Linear(32 * 7 * 7, 10)  # 注意:(32*7*7, 10)
   
       def forward(self, x):
           x = self.conv1(x)
           x = self.conv2(x)
           x = x.view(x.size(0), -1)  # 注意要将输入展开成一维向量(batch_size, 32*7*7)
           output = self.out(x)
           return output, x        # 一定注意: 可视化时 return x for visualization
   ```
   

   ![CNN_MNIST](/img/in-post/20_07/CNN_MNIST.gif)CNN结构输出:

   ```
   CNN(
     (conv1): Sequential(
       (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
       (1): ReLU()
       (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
     )
     (conv2): Sequential(
       (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
       (1): ReLU()
       (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
     )
     (out): Linear(in_features=1568, out_features=10, bias=True)
   )
   ```

   测试集前10个样本输出预测

   ```
   [7 2 1 0 4 1 4 9 5 9] prediction number
   [7 2 1 0 4 1 4 9 5 9] real number
   ```

   完整代码:

   ```python
   import os
   
   os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'
   import imageio
   from tqdm import tqdm
   import torch as t
   import torch.nn as nn
   import torch.utils.data as Data
   import matplotlib.pyplot as plt
   import torch.nn.functional as F
   import torchvision
   
   plt.style.use('seaborn')  # 设置使用的样式
   
   # for visualization
   from matplotlib import cm
   try:
       from sklearn.manifold import TSNE; HAS_SK = True
   except:
       HAS_SK = False; print('Please install sklearn for layer visualization')
   
   LR = 0.001
   BATCH_SIZE = 50  # 批训练的数据个数
   EPOCH = 8
   DOWNLOAD_MNIST = False
   
   """Mnist digits dataset"""
   if not(os.path.exists('Volumes/ArcFile/mnist/')) or not os.listdir('Volumes/ArcFile/mnist/'):
       DOWNLOAD_MNIST = True
   
   train_data = torchvision.datasets.MNIST(
       root='Volumes/ArcFile/mnist/',
       train=True,  # this is training data
       # PIL.Image or numpy.ndarray to torch.FloatTensor(C * H * W), and normalize in the range [0.0, 1.0]
       transform=torchvision.transforms.ToTensor(),
   
       download=DOWNLOAD_MNIST
   )
   # 批训练 50samples, 1 channel, 28x28 (50, 1, 28, 28)
   train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)
   # plot one example
   print(train_data.train_data.size())                 # (60000, 28, 28)
   print(train_data.train_labels.size())               # (60000)
   plt.imshow(train_data.train_data[0].numpy(), cmap='gray')
   plt.title('%i' % train_data.train_labels[0])
   plt.show()
   
   # pick 2000 samples to speed up testing
   test_data = torchvision.datasets.MNIST(root='Volumes/ArcFile/mnist/', train=False)
   # shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)
   test_x = t.unsqueeze(test_data.test_data, dim=1).type(t.FloatTensor)[:2000] / 255.
   test_y = test_data.test_labels[:2000]
   
   
   class CNN(t.nn.Module):
       def __init__(self):
           super(CNN, self).__init__()
           self.conv1 = nn.Sequential(
               # input shape (1, 28, 28) -> (16, 28, 28) -> (16, 14, 14)
               nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2),  # conv后的图片大小不变
               nn.ReLU(),
               nn.MaxPool2d(kernel_size=2))
           self.conv2 = nn.Sequential(
               # input shape (16, 14, 14) -> (32, 14, 14) -> (32, 7, 7)
               nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2),
               nn.ReLU(),
               nn.MaxPool2d(kernel_size=2))
           self.out = nn.Linear(32 * 7 * 7, 10)  # 注意:(32*7*7, 10)
   
       def forward(self, x):
           x = self.conv1(x)
           x = self.conv2(x)
           x = x.view(x.size(0), -1)  # 注意要将输入展开成一维向量(batch_size, 32*7*7)
           output = self.out(x)
           return output, x        # 一定注意: 可视化时 return x for visualization
   
   
   cnn = CNN()
   print(cnn)
   
   optimizer = t.optim.Adam(cnn.parameters(), lr=LR, betas=(0.9, 0.99))
   loss_func = nn.CrossEntropyLoss()
   
   
   def plot_with_labels(lowDWeights, labels, image_list, *param):
       plt.cla()
       X, Y = lowDWeights[:, 0], lowDWeights[:, 1]
       epoch, loss, accuracy = param
       for x, y, s in zip(X, Y, labels):
           c = cm.rainbow(int(255 * s / 9))
           plt.text(x, y, s, backgroundcolor=c, fontsize=9)
       # plt.xlim(X.min(), X.max())
       # plt.ylim(Y.min(), Y.max())
       plt.xlim(-50, 50)
       plt.ylim(-40, 40)
       plt.title('Visualize last layer')
       text = ('Epoch: %d,' % epoch + ' train loss: %.4f,' % loss.data.numpy() + ' test accuracy: %.3f' % accuracy)
       plt.text(-30, -35, text, fontdict={'size': 13, 'color': 'red'})
       plt.show()
       plt.savefig("temp.jpg")
       plt.pause(0.02)
       image_list.append(imageio.imread("temp.jpg"))  # 可以不用循环i，直接用列表形式
   
   
   def Train():
       plt.ion()
       image_list = []
       for epoch in tqdm(range(EPOCH)):
           for step, (b_x, b_y) in enumerate(train_loader):
               output = cnn(b_x)[0]  # 注意如果需要visualization时会有2个返回值,故要选择
   
               loss = loss_func(output, b_y)
               optimizer.zero_grad()  # 计算完损失就可以清除梯度了
               loss.backward()
               optimizer.step()
   
               # visualization use t-SNE
               if step % 100 == 0:
                   test_output, last_layer = cnn(test_x)
                   pred_y = t.max(test_output, 1)[1].data.numpy()
                   accuracy = float((pred_y == test_y.data.numpy()).astype(int).sum()) / float(test_y.size(0))
                   print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.3f' % accuracy)
                   if HAS_SK:
                       # Visualization of trained flatten layer (T-SNE)
                       tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)
                       plot_only = 500
                       low_dim_embs = tsne.fit_transform(last_layer.data.numpy()[:plot_only, :])
                       labels = test_y.numpy()[:plot_only]
                       plot_with_labels(low_dim_embs, labels, image_list, epoch, loss, accuracy)  # lowDWeights, labels
       plt.ioff()
       imageio.mimsave('CNN_MNIST.gif', image_list, 'GIF', duration=0.2)
   
       t.save(cnn, './Try_ModelSaved/cnn_mnist.pkl')  # 保存整个网络
   
   
   def Test():
       net2 = t.load('./Try_ModelSaved/cnn_mnist.pkl')  # restore entire net1 to net2
       test_output = net2(test_x[:10])
       pred_y = t.max(test_output[0], 1)[1].data.numpy().squeeze()
       print(pred_y, 'prediction number')
       print(test_y[:10].numpy(), 'real number')
   
   
   Train()
   Test()
   ```

# RNN — 序列化分析

## 介绍

1. 具有记忆之前知识的能力

<img src="/img/in-post/20_07/rnn4.png" alt="rnn4.png" style="zoom:50%;" />

2. 梯度消失或者梯度爆炸的问题(取决于w大于1还是小于1)

   <img src="/img/in-post/20_07/lstm3.png" alt="lstm3.png" style="zoom:50%;" />

   <img src="/img/in-post/20_07/lstm4.png" alt="lstm4.png" style="zoom:50%;" />

   

# LSTM — 延缓记忆衰退

带控制器 — 输入控制,输出控制,忘记控制

<img src="/img/in-post/20_07/lstm5.png" alt="lstm5.png" style="zoom:50%;" />

参数

```python
TIME_STEP = 28      # rnn 时间步数 / 图片高度
INPUT_SIZE = 28     # rnn 每步输入值 / 图片每行像素
```

RNN模型: 和以前一样, 我们用一个 class 来建立 RNN 模型. 这个 RNN 整体流程是

1. `(input0, state0)` -> `LSTM` -> `(output0, state1)`;
2. `(input1, state1)` -> `LSTM` -> `(output1, state2)`;
3. ...
4. `(inputN, stateN)`-> `LSTM` -> `(outputN, stateN+1)`;
5. `outputN` -> `Linear` -> `prediction`. 通过`LSTM`**分析每一时刻的值**, 并且将这一时刻和前面时刻的理解合并在一起, 生成当前时刻对前面数据的理解或记忆. 传递这种理解给下一时刻分析.

输出:

```
torch.Size([60000, 28, 28])
torch.Size([60000])
RNN(
  (rnn): LSTM(28, 64, batch_first=True)
  (out): Linear(in_features=64, out_features=10, bias=True)
)
Epoch:  0 | train loss: 2.2925 | test accuracy: 0.10
Epoch:  0 | train loss: 1.1347 | test accuracy: 0.55
Epoch:  0 | train loss: 1.0238 | test accuracy: 0.68
Epoch:  0 | train loss: 0.4887 | test accuracy: 0.81
Epoch:  0 | train loss: 0.4760 | test accuracy: 0.85
Epoch:  0 | train loss: 0.2999 | test accuracy: 0.86
Epoch:  0 | train loss: 0.3342 | test accuracy: 0.89
Epoch:  0 | train loss: 0.4210 | test accuracy: 0.93
Epoch:  0 | train loss: 0.1264 | test accuracy: 0.93
Epoch:  0 | train loss: 0.3789 | test accuracy: 0.93
Epoch:  0 | train loss: 0.2171 | test accuracy: 0.92
Epoch:  0 | train loss: 0.2132 | test accuracy: 0.94
Epoch:  0 | train loss: 0.2326 | test accuracy: 0.93
Epoch:  0 | train loss: 0.0600 | test accuracy: 0.94
Epoch:  0 | train loss: 0.2595 | test accuracy: 0.94
Epoch:  0 | train loss: 0.0987 | test accuracy: 0.95
Epoch:  0 | train loss: 0.1818 | test accuracy: 0.94
Epoch:  0 | train loss: 0.3106 | test accuracy: 0.96
Epoch:  0 | train loss: 0.1822 | test accuracy: 0.95
[7 2 1 0 4 1 4 9 5 9] prediction number
[7 2 1 0 4 1 4 9 5 9] real number
```

完整程序

# Reference

1. 莫烦Python



