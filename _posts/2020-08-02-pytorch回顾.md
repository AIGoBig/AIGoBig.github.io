# Introduction

## Why pytorch？

### 更加“Python化”，更易于使用

每一个Pytorch示例（CV和NLP）都有共同的结构：

```python
data/
experiments/
model/
	net.py：指定神经网络架构、损失函数和评估指标。
	data_loader.py：指定数据应如何馈送到网络。
train.py：包含主训练循环。
evaluate.py：包含用于评估模型的主循环。
search_hyperparams.py
synthesize_results.py
evaluate.py
utils.py：用于处理超参数 / 日志 / 存储模型的实用功能。
```

### 有用的库

下面是一个综合列表，列出了计算机视觉、自然语言处理和生成库等不同领域的一些项目：

- pro_gan_pytorch：利用 ProGAN 功能。
- BoTorch：使用[贝叶斯](https://www.infoq.cn/article/2014/07/programming-language-bayes)优化。
- ParlAI：用于共享、训练和测试对话模型。
- OpenNMT-py：用于实现神经机器翻译系统。
- MUSE：用于多语言词嵌入。
- **skorch：用于将 scikit-learn 代码与 PyTorch 融合。**

### 易于实现数据并行

Distributed Data-Parallel（分布式数据并行）是 PyTorch 的一项特性，你可以将其与 Data-Parallel（数据并行）结合使用来处理需要大型数据集和模型的用例。

为实现数据并行，使用了`torch.nn.DataParallel`类

### 增加了对移动设备的支持

如Android和IOS设备部署的支持

**PyTorch Mobile 入门：**

- Android：[ https://pytorch.org/mobile/android](https://pytorch.org/mobile/android)
- iOS：[ https://pytorch.org/mobile/ios](https://pytorch.org/mobile/ios)

### 易于调试

pytorch的动态计算图允许在代码执行时进行动态修改和快速调试

# 使用方式

## torch 与 numpy

互相转换

```python
np_data = np.arange(6).reshape((2, 3))
torch_data = torch.from_numpy(np_data)
tensor2array = torch_data.numpy()
```

运算形式

1. 注意torch中的数据形式是`Tensor`

```python
# abs 绝对值计算
data = [-1, -2, 1, 2]
tensor = torch.FloatTensor(data)  # 转换成32位浮点 tensor
print(
    '\nabs',
    '\nnumpy: ', np.abs(data),          # [1 2 1 2]
    '\ntorch: ', torch.abs(tensor)      # [1 2 1 2]
)
```

2. Autograd automatically supports Tensors with requires_grad set to True.  计算图可以通过链式法则求导。如果`variables`中的任何一个`variable`是 非标量(`non-scalar`)的，且`requires_grad=True`。
3. 
4. 



